{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone_project_merged.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "JjLYDGAUujy4",
        "ecPo0Jetse39",
        "oq_sLBsSse3_"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoIQFdjR-Lid",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDXUu5iW-Lij",
        "colab_type": "text"
      },
      "source": [
        "Load Python modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGcmXwG--Lio",
        "colab_type": "code",
        "outputId": "47e95cf3-45cf-44db-ef3d-dd09c88b8ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip3 install symspellpy\n",
        "!pip3 install keras_bert\n",
        "from symspellpy.symspellpy import SymSpell\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tensorflow.python.client import device_lib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding,Dropout,Lambda,Dense,Input,LSTM,Concatenate,Flatten,Add,Reshape,GlobalAveragePooling1D,GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import Model,Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import sys\n",
        "assert sys.version_info[0] >= 3\n",
        "print(tf.VERSION)\n",
        "print(\"Modules loaded!\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting symspellpy\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/c2/8a15e2d16d22644afa208317a445f46b1e3157ad681dc5f31d6a25a8113e/symspellpy-6.3.9-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.16.4)\n",
            "Installing collected packages: symspellpy\n",
            "Successfully installed symspellpy-6.3.9\n",
            "Collecting keras_bert\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/1a/54cd6e0832fc457de5fe1d0f703bd519690a466060a886bea4e74fb47771/keras-bert-0.75.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_bert) (1.16.4)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_bert) (2.2.4)\n",
            "Collecting keras-transformer>=0.30.0 (from keras_bert)\n",
            "  Downloading https://files.pythonhosted.org/packages/83/4c/972325395b38547df8a74be89e980922c1dc9f921cc2eb613e086c6bc632/keras-transformer-0.30.0.tar.gz\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.1.0)\n",
            "Collecting keras-pos-embd>=0.10.0 (from keras-transformer>=0.30.0->keras_bert)\n",
            "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
            "Collecting keras-multi-head>=0.22.0 (from keras-transformer>=0.30.0->keras_bert)\n",
            "  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\n",
            "Collecting keras-layer-normalization>=0.12.0 (from keras-transformer>=0.30.0->keras_bert)\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/f3/a92ce51219280eea003911722046db17eaebf5f26679a73887a5c357abe4/keras-layer-normalization-0.13.0.tar.gz\n",
            "Collecting keras-position-wise-feed-forward>=0.5.0 (from keras-transformer>=0.30.0->keras_bert)\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
            "Collecting keras-embed-sim>=0.7.0 (from keras-transformer>=0.30.0->keras_bert)\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\n",
            "Collecting keras-self-attention==0.41.0 (from keras-multi-head>=0.22.0->keras-transformer>=0.30.0->keras_bert)\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\n",
            "Building wheels for collected packages: keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.75.0-cp36-none-any.whl size=37451 sha256=9965716b9ec6216278a332a7f96c6d13c8f8883cdb7a84d7579f5c3a9cf661bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/e8/31/33a3f6dd5ccacf96fea75724af721f6f02a3d5a05c7b2d65cc\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.30.0-cp36-none-any.whl size=13388 sha256=b120f891b810fcd8b7907ba75115a6e9d1569928a77200cdfa632ce4b29487da\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/06/e3/172763eea3a0b3046c91a75ec778c54e55f96ee0efdb79c044\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7553 sha256=ec80282cf90e7e9cf1eec8835a572fd58b029efc59029c43e1c9f6265360c5fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=3dd254b27bb63d74aeaf4caeb22c39d2c5c2abb20b4aa78978c0d27f5c080554\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.13.0-cp36-none-any.whl size=5209 sha256=a490340f253b81107713fd1819e768b80394abeb3a3cf95a7d7ed6e56616ed47\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/2b/71/d1d06f71d78c46a9912dc89a5bb46f357cf64fa05883fadc64\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5623 sha256=7479f20287360ab5fb47bb4ae39710c717a83a603da17e9485232a2651acca05\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4677 sha256=8bee7a2db6aa58488049a57f8ddaf534533e2672d3b76da781f0759b2b97e197\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17289 sha256=2cd11eaf5c275a6afec8a0333028cf8d52c6abb08cc6d07dad414c349368623b\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\n",
            "Successfully built keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
            "Installing collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert\n",
            "Successfully installed keras-bert-0.75.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.13.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.30.0\n",
            "1.14.0\n",
            "Modules loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXFuFons-LjA",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqjrxOes-LjD",
        "colab_type": "text"
      },
      "source": [
        "For the preprocessing step, we will create two dictionaries. One will be used to map questions to articles, while the other will be used to map questions and the contents of the articles to the answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8UbZDe--LjG",
        "colab_type": "text"
      },
      "source": [
        "### Loading JSON datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I79-hb5dCBfy",
        "colab_type": "code",
        "outputId": "77ee218e-12a6-4c7e-a03b-af2f741828d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "!wget -nc https://github.com/moonman239/Capstone-project/raw/master/data.zip -O data.zip\n",
        "!unzip data.zip\n",
        "assert os.path.isfile(\"train-v1.1.json\"),\"Non-existent file\"\n",
        "print(\"JSON datasets downloaded.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘data.zip’ already there; not retrieving.\n",
            "Archive:  data.zip\n",
            "replace dev-v1.1.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: JSON datasets downloaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fgU382EF26d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import re\n",
        "#regex = re.compile(r'\\W+')\n",
        "def readFile(filename):\n",
        "  with open(filename) as file:\n",
        "    fields = []\n",
        "    JSON = json.loads(file.read())\n",
        "    articles = []\n",
        "    for article in JSON[\"data\"]:\n",
        "      articleTitle = article[\"title\"]\n",
        "      article_body = []\n",
        "      for paragraph in article[\"paragraphs\"]:\n",
        "        paragraphContext = paragraph[\"context\"]\n",
        "        article_body.append(paragraphContext)\n",
        "        for qas in paragraph[\"qas\"]:\n",
        "          question = qas[\"question\"]\n",
        "          answer = qas[\"answers\"][0]\n",
        "          fields.append({\"question\":question,\"answer_text\":answer[\"text\"],\"answer_start\":answer[\"answer_start\"],\"paragraph_context\":paragraphContext,\"article_title\":articleTitle})\n",
        "      article_body = \"\\\\n\".join(article_body)\n",
        "      article = {\"title\":articleTitle,\"body\":article_body}\n",
        "      articles.append(article)\n",
        "  fields = pd.DataFrame(fields)\n",
        "  #fields[\"question\"] = fields[\"question\"].str.replace(regex,\" \")\n",
        "  assert not (fields[\"question\"].str.contains(\"catalanswhat\").any())\n",
        "  #fields[\"paragraph_context\"] = fields[\"paragraph_context\"].str.replace(regex,\" \")\n",
        "  #fields[\"answer_text\"] = fields[\"answer_text\"].str.replace(regex,\" \")\n",
        "  assert not (fields[\"paragraph_context\"].str.contains(\"catalanswhat\").any())\n",
        "  fields[\"article_title\"] = fields[\"article_title\"].str.replace(\"_\",\" \")\n",
        "  assert not (fields[\"article_title\"].str.contains(\"catalanswhat\").any())\n",
        "  return fields,articles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1Ql0r8fOpCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainingData,training_articles = readFile(\"train-v1.1.json\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "trainingData,crossValidationData = train_test_split(trainingData)\n",
        "devData,dev_articles = readFile(\"dev-v1.1.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XufEvRe0ap_R",
        "colab_type": "code",
        "outputId": "a347893a-811a-46a3-894a-3b466156daa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trainingData"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>article_title</th>\n",
              "      <th>paragraph_context</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>515</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>188</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What is in front of the Notre Dame Main Building?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>279</td>\n",
              "      <td>the Main Building</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>381</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What is the Grotto at Notre Dame?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>92</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What sits on top of the Main Building at Notre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>248</td>\n",
              "      <td>September 1876</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>As at most other universities, Notre Dame's st...</td>\n",
              "      <td>When did the Scholastic Magazine of Notre dame...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>441</td>\n",
              "      <td>twice</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>As at most other universities, Notre Dame's st...</td>\n",
              "      <td>How often is Notre Dame's the Juggler published?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>598</td>\n",
              "      <td>The Observer</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>As at most other universities, Notre Dame's st...</td>\n",
              "      <td>What is the daily student paper at Notre Dame ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>126</td>\n",
              "      <td>three</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>As at most other universities, Notre Dame's st...</td>\n",
              "      <td>How many student news papers are found at Notr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>908</td>\n",
              "      <td>1987</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>As at most other universities, Notre Dame's st...</td>\n",
              "      <td>In what year did the student paper Common Sens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>119</td>\n",
              "      <td>Rome</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university is the major seat of the Congre...</td>\n",
              "      <td>Where is the headquarters of the Congregation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>145</td>\n",
              "      <td>Moreau Seminary</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university is the major seat of the Congre...</td>\n",
              "      <td>What is the primary seminary of the Congregati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>234</td>\n",
              "      <td>Old College</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university is the major seat of the Congre...</td>\n",
              "      <td>What is the oldest structure at Notre Dame?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>356</td>\n",
              "      <td>Retired priests and brothers</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university is the major seat of the Congre...</td>\n",
              "      <td>What individuals live at Fatima House at Notre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>675</td>\n",
              "      <td>Buechner Prize for Preaching</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university is the major seat of the Congre...</td>\n",
              "      <td>Which prize did Frederick Buechner create?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>487</td>\n",
              "      <td>eight</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The College of Engineering was established in ...</td>\n",
              "      <td>How many BS level degrees are offered in the C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>46</td>\n",
              "      <td>1920</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The College of Engineering was established in ...</td>\n",
              "      <td>In what year was the College of Engineering at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>126</td>\n",
              "      <td>the College of Science</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The College of Engineering was established in ...</td>\n",
              "      <td>Before the creation of the College of Engineer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>271</td>\n",
              "      <td>five</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The College of Engineering was established in ...</td>\n",
              "      <td>How many departments are within the Stinson-Re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>155</td>\n",
              "      <td>the 1870s</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The College of Engineering was established in ...</td>\n",
              "      <td>The College of Science began to offer civil en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>496</td>\n",
              "      <td>Learning Resource Center</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>All of Notre Dame's undergraduate students are...</td>\n",
              "      <td>What entity provides help with the management ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>68</td>\n",
              "      <td>five</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>All of Notre Dame's undergraduate students are...</td>\n",
              "      <td>How many colleges for undergraduates are at No...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>155</td>\n",
              "      <td>The First Year of Studies program</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>All of Notre Dame's undergraduate students are...</td>\n",
              "      <td>What was created at Notre Dame in 1962 to assi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>647</td>\n",
              "      <td>U.S. News &amp; World Report</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>All of Notre Dame's undergraduate students are...</td>\n",
              "      <td>Which organization declared the First Year of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>358</td>\n",
              "      <td>1924</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university first offered graduate degrees,...</td>\n",
              "      <td>The granting of Doctorate degrees first occurr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>624</td>\n",
              "      <td>Master of Divinity</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university first offered graduate degrees,...</td>\n",
              "      <td>What type of degree is an M.Div.?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1163</td>\n",
              "      <td>Alliance for Catholic Education</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university first offered graduate degrees,...</td>\n",
              "      <td>Which program at Notre Dame offers a Master of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>92</td>\n",
              "      <td>1854</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university first offered graduate degrees,...</td>\n",
              "      <td>In what year was a Master of Arts course first...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>757</td>\n",
              "      <td>Department of Pre-Professional Studies</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university first offered graduate degrees,...</td>\n",
              "      <td>Which department at Notre Dame is the only one...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>4</td>\n",
              "      <td>Joan B. Kroc Institute for International Peace...</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The Joan B. Kroc Institute for International P...</td>\n",
              "      <td>What institute at Notre Dame studies  the reas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87569</th>\n",
              "      <td>209</td>\n",
              "      <td>Gyaneshwar</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Sikhism is practiced primarily in Gurudwara at...</td>\n",
              "      <td>Where can a temple of the Jain faith be found?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87570</th>\n",
              "      <td>355</td>\n",
              "      <td>300</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Sikhism is practiced primarily in Gurudwara at...</td>\n",
              "      <td>Kathmandu valley is home to about how many Bah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87571</th>\n",
              "      <td>427</td>\n",
              "      <td>Shantinagar, Baneshwor</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Sikhism is practiced primarily in Gurudwara at...</td>\n",
              "      <td>Where is the Baha'i national office located in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87572</th>\n",
              "      <td>633</td>\n",
              "      <td>4.2</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Sikhism is practiced primarily in Gurudwara at...</td>\n",
              "      <td>About what percentage of the Nepali population...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87573</th>\n",
              "      <td>728</td>\n",
              "      <td>170</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Sikhism is practiced primarily in Gurudwara at...</td>\n",
              "      <td>About how many Christian houses of worship exi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87574</th>\n",
              "      <td>46</td>\n",
              "      <td>Tribhuwan</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Institute of Medicine, the central college of ...</td>\n",
              "      <td>Of what university is the Institute of Medicin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87575</th>\n",
              "      <td>123</td>\n",
              "      <td>Maharajgunj</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Institute of Medicine, the central college of ...</td>\n",
              "      <td>In what part of Kathmandu is the Institute of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87576</th>\n",
              "      <td>219</td>\n",
              "      <td>1978</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Institute of Medicine, the central college of ...</td>\n",
              "      <td>When did the Institute of Medicine begin to of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87577</th>\n",
              "      <td>425</td>\n",
              "      <td>Kathmandu University School of Medical Sciences</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Institute of Medicine, the central college of ...</td>\n",
              "      <td>What does KUSMS stand for?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87578</th>\n",
              "      <td>377</td>\n",
              "      <td>National Academy of Medical Sciences</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Institute of Medicine, the central college of ...</td>\n",
              "      <td>What institution of tertiary education is know...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87579</th>\n",
              "      <td>0</td>\n",
              "      <td>Football</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Football and Cricket are the most popular spor...</td>\n",
              "      <td>Along with cricket, what sport is highly popul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87580</th>\n",
              "      <td>160</td>\n",
              "      <td>All Nepal Football Association</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Football and Cricket are the most popular spor...</td>\n",
              "      <td>What body oversees soccer in Nepal?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87581</th>\n",
              "      <td>498</td>\n",
              "      <td>25,000</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Football and Cricket are the most popular spor...</td>\n",
              "      <td>How many people can fit in Dasarath Rangasala ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87582</th>\n",
              "      <td>430</td>\n",
              "      <td>Tripureshwor</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Football and Cricket are the most popular spor...</td>\n",
              "      <td>In what part of Kathmandu is Dasarath Rangasal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87583</th>\n",
              "      <td>628</td>\n",
              "      <td>Chinese</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Football and Cricket are the most popular spor...</td>\n",
              "      <td>Who assisted Nepal in renovating Dasarath Rang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87584</th>\n",
              "      <td>54</td>\n",
              "      <td>17,182</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The total length of roads in Nepal is recorded...</td>\n",
              "      <td>As of 2004, how many kilometers of road existe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87585</th>\n",
              "      <td>289</td>\n",
              "      <td>hilly terrain</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The total length of roads in Nepal is recorded...</td>\n",
              "      <td>Why is travel in Kathmandu mainly via automobi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87586</th>\n",
              "      <td>500</td>\n",
              "      <td>BP</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The total length of roads in Nepal is recorded...</td>\n",
              "      <td>What highway connecting Kathmandu to elsewhere...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87587</th>\n",
              "      <td>457</td>\n",
              "      <td>west</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The total length of roads in Nepal is recorded...</td>\n",
              "      <td>In what direction out of Kathmandu does the Pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87588</th>\n",
              "      <td>466</td>\n",
              "      <td>Araniko</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The total length of roads in Nepal is recorded...</td>\n",
              "      <td>If one wished to travel north out of Kathmandu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87589</th>\n",
              "      <td>71</td>\n",
              "      <td>Tribhuvan International Airport</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The main international airport serving Kathman...</td>\n",
              "      <td>What is Nepal's primary airport for internatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87590</th>\n",
              "      <td>134</td>\n",
              "      <td>6</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The main international airport serving Kathman...</td>\n",
              "      <td>Starting in the center of Kathmandu, how many ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87591</th>\n",
              "      <td>297</td>\n",
              "      <td>22</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The main international airport serving Kathman...</td>\n",
              "      <td>How many airlines use Tribhuvan International ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87592</th>\n",
              "      <td>698</td>\n",
              "      <td>Amsterdam</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The main international airport serving Kathman...</td>\n",
              "      <td>From what city does Arkefly offer nonstop flig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87593</th>\n",
              "      <td>734</td>\n",
              "      <td>Turkish Airlines</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The main international airport serving Kathman...</td>\n",
              "      <td>Who operates flights between Kathmandu and Ist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87594</th>\n",
              "      <td>229</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
              "      <td>In what US state did Kathmandu first establish...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87595</th>\n",
              "      <td>414</td>\n",
              "      <td>Rangoon</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
              "      <td>What was Yangon previously known as?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87596</th>\n",
              "      <td>476</td>\n",
              "      <td>Minsk</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
              "      <td>With what Belorussian city does Kathmandu have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87597</th>\n",
              "      <td>199</td>\n",
              "      <td>1975</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
              "      <td>In what year did Kathmandu create its initial ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87598</th>\n",
              "      <td>0</td>\n",
              "      <td>Kathmandu Metropolitan City</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Kathmandu Metropolitan City (KMC), in order to...</td>\n",
              "      <td>What is KMC an initialism of?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>87599 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       answer_start  ...                                           question\n",
              "0               515  ...  To whom did the Virgin Mary allegedly appear i...\n",
              "1               188  ...  What is in front of the Notre Dame Main Building?\n",
              "2               279  ...  The Basilica of the Sacred heart at Notre Dame...\n",
              "3               381  ...                  What is the Grotto at Notre Dame?\n",
              "4                92  ...  What sits on top of the Main Building at Notre...\n",
              "5               248  ...  When did the Scholastic Magazine of Notre dame...\n",
              "6               441  ...   How often is Notre Dame's the Juggler published?\n",
              "7               598  ...  What is the daily student paper at Notre Dame ...\n",
              "8               126  ...  How many student news papers are found at Notr...\n",
              "9               908  ...  In what year did the student paper Common Sens...\n",
              "10              119  ...  Where is the headquarters of the Congregation ...\n",
              "11              145  ...  What is the primary seminary of the Congregati...\n",
              "12              234  ...        What is the oldest structure at Notre Dame?\n",
              "13              356  ...  What individuals live at Fatima House at Notre...\n",
              "14              675  ...         Which prize did Frederick Buechner create?\n",
              "15              487  ...  How many BS level degrees are offered in the C...\n",
              "16               46  ...  In what year was the College of Engineering at...\n",
              "17              126  ...  Before the creation of the College of Engineer...\n",
              "18              271  ...  How many departments are within the Stinson-Re...\n",
              "19              155  ...  The College of Science began to offer civil en...\n",
              "20              496  ...  What entity provides help with the management ...\n",
              "21               68  ...  How many colleges for undergraduates are at No...\n",
              "22              155  ...  What was created at Notre Dame in 1962 to assi...\n",
              "23              647  ...  Which organization declared the First Year of ...\n",
              "24              358  ...  The granting of Doctorate degrees first occurr...\n",
              "25              624  ...                  What type of degree is an M.Div.?\n",
              "26             1163  ...  Which program at Notre Dame offers a Master of...\n",
              "27               92  ...  In what year was a Master of Arts course first...\n",
              "28              757  ...  Which department at Notre Dame is the only one...\n",
              "29                4  ...  What institute at Notre Dame studies  the reas...\n",
              "...             ...  ...                                                ...\n",
              "87569           209  ...     Where can a temple of the Jain faith be found?\n",
              "87570           355  ...  Kathmandu valley is home to about how many Bah...\n",
              "87571           427  ...  Where is the Baha'i national office located in...\n",
              "87572           633  ...  About what percentage of the Nepali population...\n",
              "87573           728  ...  About how many Christian houses of worship exi...\n",
              "87574            46  ...  Of what university is the Institute of Medicin...\n",
              "87575           123  ...  In what part of Kathmandu is the Institute of ...\n",
              "87576           219  ...  When did the Institute of Medicine begin to of...\n",
              "87577           425  ...                         What does KUSMS stand for?\n",
              "87578           377  ...  What institution of tertiary education is know...\n",
              "87579             0  ...  Along with cricket, what sport is highly popul...\n",
              "87580           160  ...                What body oversees soccer in Nepal?\n",
              "87581           498  ...  How many people can fit in Dasarath Rangasala ...\n",
              "87582           430  ...  In what part of Kathmandu is Dasarath Rangasal...\n",
              "87583           628  ...  Who assisted Nepal in renovating Dasarath Rang...\n",
              "87584            54  ...  As of 2004, how many kilometers of road existe...\n",
              "87585           289  ...  Why is travel in Kathmandu mainly via automobi...\n",
              "87586           500  ...  What highway connecting Kathmandu to elsewhere...\n",
              "87587           457  ...  In what direction out of Kathmandu does the Pr...\n",
              "87588           466  ...  If one wished to travel north out of Kathmandu...\n",
              "87589            71  ...  What is Nepal's primary airport for internatio...\n",
              "87590           134  ...  Starting in the center of Kathmandu, how many ...\n",
              "87591           297  ...  How many airlines use Tribhuvan International ...\n",
              "87592           698  ...  From what city does Arkefly offer nonstop flig...\n",
              "87593           734  ...  Who operates flights between Kathmandu and Ist...\n",
              "87594           229  ...  In what US state did Kathmandu first establish...\n",
              "87595           414  ...               What was Yangon previously known as?\n",
              "87596           476  ...  With what Belorussian city does Kathmandu have...\n",
              "87597           199  ...  In what year did Kathmandu create its initial ...\n",
              "87598             0  ...                      What is KMC an initialism of?\n",
              "\n",
              "[87599 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4Gn1pjgV30v",
        "colab_type": "code",
        "outputId": "55878139-d0e7-47df-d700-a17f25dcb376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "devData"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>article_title</th>\n",
              "      <th>paragraph_context</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>177</td>\n",
              "      <td>Denver Broncos</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Which NFL team represented the AFC at Super Bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>249</td>\n",
              "      <td>Carolina Panthers</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Which NFL team represented the NFC at Super Bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>403</td>\n",
              "      <td>Santa Clara, California</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Where did Super Bowl 50 take place?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>177</td>\n",
              "      <td>Denver Broncos</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Which NFL team won Super Bowl 50?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>488</td>\n",
              "      <td>gold</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What color was used to emphasize the 50th anni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>487</td>\n",
              "      <td>\"golden anniversary\"</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What was the theme of Super Bowl 50?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>334</td>\n",
              "      <td>February 7, 2016</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What day was the game played on?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>133</td>\n",
              "      <td>American Football Conference</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What is the AFC short for?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>487</td>\n",
              "      <td>\"golden anniversary\"</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What was the theme of Super Bowl 50?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>133</td>\n",
              "      <td>American Football Conference</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What does AFC stand for?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>334</td>\n",
              "      <td>February 7, 2016</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What day was the Super Bowl played on?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>177</td>\n",
              "      <td>Denver Broncos</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Who won Super Bowl 50?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>355</td>\n",
              "      <td>Levi's Stadium</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What venue did Super Bowl 50 take place in?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>403</td>\n",
              "      <td>Santa Clara</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What city did Super Bowl 50 take place in?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>693</td>\n",
              "      <td>Super Bowl L</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>If Roman numerals were used, what would Super ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>116</td>\n",
              "      <td>2015</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Super Bowl 50 decided the NFL champion for wha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>116</td>\n",
              "      <td>2015</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What year did the Denver Broncos secure a Supe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>403</td>\n",
              "      <td>Santa Clara</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What city did Super Bowl 50 take place in?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>355</td>\n",
              "      <td>Levi's Stadium</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What stadium did Super Bowl 50 take place in?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>267</td>\n",
              "      <td>24–10</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What was the final score of Super Bowl 50?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>334</td>\n",
              "      <td>February 7, 2016</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What month, day and year did Super Bowl 50 tak...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>116</td>\n",
              "      <td>2015</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What year was Super Bowl 50?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>177</td>\n",
              "      <td>Denver Broncos</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What team was the AFC champion?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>249</td>\n",
              "      <td>Carolina Panthers</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What team was the NFC champion?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>177</td>\n",
              "      <td>Denver Broncos</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Who won Super Bowl 50?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>116</td>\n",
              "      <td>2015</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Super Bowl 50 determined the NFL champion for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>177</td>\n",
              "      <td>Denver Broncos</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Which team won Super Bowl 50.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>403</td>\n",
              "      <td>Santa Clara, California.</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>Where was Super Bowl 50 held?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>Super Bowl</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>The name of the NFL championship game is?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>177</td>\n",
              "      <td>Denver Broncos</td>\n",
              "      <td>Super Bowl 50</td>\n",
              "      <td>Super Bowl 50 was an American football game to...</td>\n",
              "      <td>What 2015 NFL team one the AFC playoff?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10540</th>\n",
              "      <td>132</td>\n",
              "      <td>pressure terms</td>\n",
              "      <td>Force</td>\n",
              "      <td>where  is the relevant cross-sectional area fo...</td>\n",
              "      <td>What is used to calculate cross section area i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10541</th>\n",
              "      <td>132</td>\n",
              "      <td>pressure terms</td>\n",
              "      <td>Force</td>\n",
              "      <td>where  is the relevant cross-sectional area fo...</td>\n",
              "      <td>What are associated with normal forces?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10542</th>\n",
              "      <td>113</td>\n",
              "      <td>formalism</td>\n",
              "      <td>Force</td>\n",
              "      <td>where  is the relevant cross-sectional area fo...</td>\n",
              "      <td>What includes pressure terms when calculating ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10543</th>\n",
              "      <td>77</td>\n",
              "      <td>rotational equivalent for position</td>\n",
              "      <td>Force</td>\n",
              "      <td>Torque is the rotation equivalent of force in ...</td>\n",
              "      <td>What is the force equivalent of torque compare...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10544</th>\n",
              "      <td>346</td>\n",
              "      <td>unbalanced torque</td>\n",
              "      <td>Force</td>\n",
              "      <td>Torque is the rotation equivalent of force in ...</td>\n",
              "      <td>What would change the rotational inertia of a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10545</th>\n",
              "      <td>375</td>\n",
              "      <td>Newton's Second Law of Motion</td>\n",
              "      <td>Force</td>\n",
              "      <td>Torque is the rotation equivalent of force in ...</td>\n",
              "      <td>To calculate instant angular acceleration of a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10546</th>\n",
              "      <td>291</td>\n",
              "      <td>toward the center of the curving path</td>\n",
              "      <td>Force</td>\n",
              "      <td>where  is the mass of the object,  is the velo...</td>\n",
              "      <td>Where does centripetal force go?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10547</th>\n",
              "      <td>346</td>\n",
              "      <td>perpendicular</td>\n",
              "      <td>Force</td>\n",
              "      <td>where  is the mass of the object,  is the velo...</td>\n",
              "      <td>How do centripetal forces act in relation to v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10548</th>\n",
              "      <td>837</td>\n",
              "      <td>centripetal</td>\n",
              "      <td>Force</td>\n",
              "      <td>where  is the mass of the object,  is the velo...</td>\n",
              "      <td>What force changes an objects direction of tra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10549</th>\n",
              "      <td>829</td>\n",
              "      <td>radial</td>\n",
              "      <td>Force</td>\n",
              "      <td>where  is the mass of the object,  is the velo...</td>\n",
              "      <td>What is another word for centripetal force?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10550</th>\n",
              "      <td>729</td>\n",
              "      <td>tangential force</td>\n",
              "      <td>Force</td>\n",
              "      <td>where  is the mass of the object,  is the velo...</td>\n",
              "      <td>What is resposible for speeding up or slowing ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10551</th>\n",
              "      <td>127</td>\n",
              "      <td>kinetic</td>\n",
              "      <td>Force</td>\n",
              "      <td>A conservative force that acts on a closed sys...</td>\n",
              "      <td>What is the only form potential energy can cha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10552</th>\n",
              "      <td>138</td>\n",
              "      <td>potential</td>\n",
              "      <td>Force</td>\n",
              "      <td>A conservative force that acts on a closed sys...</td>\n",
              "      <td>What is the only form kinetic energy can chang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10553</th>\n",
              "      <td>196</td>\n",
              "      <td>net mechanical energy</td>\n",
              "      <td>Force</td>\n",
              "      <td>A conservative force that acts on a closed sys...</td>\n",
              "      <td>What is preserved in a closed system of forces...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10554</th>\n",
              "      <td>330</td>\n",
              "      <td>difference in potential energy</td>\n",
              "      <td>Force</td>\n",
              "      <td>A conservative force that acts on a closed sys...</td>\n",
              "      <td>What is the force between two locations relate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10555</th>\n",
              "      <td>434</td>\n",
              "      <td>artifact</td>\n",
              "      <td>Force</td>\n",
              "      <td>A conservative force that acts on a closed sys...</td>\n",
              "      <td>What is the force called rgarding a potential ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10556</th>\n",
              "      <td>58</td>\n",
              "      <td>forces</td>\n",
              "      <td>Force</td>\n",
              "      <td>For certain physical scenarios, it is impossib...</td>\n",
              "      <td>What is sometimes impossible to model?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10557</th>\n",
              "      <td>81</td>\n",
              "      <td>gradient of potentials</td>\n",
              "      <td>Force</td>\n",
              "      <td>For certain physical scenarios, it is impossib...</td>\n",
              "      <td>Why are some forces due to that are impossible...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10558</th>\n",
              "      <td>252</td>\n",
              "      <td>friction</td>\n",
              "      <td>Force</td>\n",
              "      <td>For certain physical scenarios, it is impossib...</td>\n",
              "      <td>What do electrostatic gradiient potentials cre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10559</th>\n",
              "      <td>430</td>\n",
              "      <td>Nonconservative</td>\n",
              "      <td>Force</td>\n",
              "      <td>For certain physical scenarios, it is impossib...</td>\n",
              "      <td>Tension, compression, and drag are what kind o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10560</th>\n",
              "      <td>134</td>\n",
              "      <td>statistical mechanics</td>\n",
              "      <td>Force</td>\n",
              "      <td>The connection between macroscopic nonconserva...</td>\n",
              "      <td>In what treatment are nonconservative and cons...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10561</th>\n",
              "      <td>188</td>\n",
              "      <td>nonconservative forces</td>\n",
              "      <td>Force</td>\n",
              "      <td>The connection between macroscopic nonconserva...</td>\n",
              "      <td>What changes macroscopic closed system energies?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10562</th>\n",
              "      <td>188</td>\n",
              "      <td>nonconservative forces</td>\n",
              "      <td>Force</td>\n",
              "      <td>The connection between macroscopic nonconserva...</td>\n",
              "      <td>What is the exchange of heat associated with?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10563</th>\n",
              "      <td>331</td>\n",
              "      <td>Second</td>\n",
              "      <td>Force</td>\n",
              "      <td>The connection between macroscopic nonconserva...</td>\n",
              "      <td>What is the law of thermodynamics associated w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10564</th>\n",
              "      <td>361</td>\n",
              "      <td>nonconservative forces</td>\n",
              "      <td>Force</td>\n",
              "      <td>The connection between macroscopic nonconserva...</td>\n",
              "      <td>What makes energy changes in a closed system?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10565</th>\n",
              "      <td>82</td>\n",
              "      <td>kilogram-force</td>\n",
              "      <td>Force</td>\n",
              "      <td>The pound-force has a metric counterpart, less...</td>\n",
              "      <td>What is the metric term less used than the New...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10566</th>\n",
              "      <td>114</td>\n",
              "      <td>kilopond</td>\n",
              "      <td>Force</td>\n",
              "      <td>The pound-force has a metric counterpart, less...</td>\n",
              "      <td>What is the kilogram-force sometimes reffered ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10567</th>\n",
              "      <td>274</td>\n",
              "      <td>slug</td>\n",
              "      <td>Force</td>\n",
              "      <td>The pound-force has a metric counterpart, less...</td>\n",
              "      <td>What is a very seldom used unit of mass in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10568</th>\n",
              "      <td>712</td>\n",
              "      <td>kip</td>\n",
              "      <td>Force</td>\n",
              "      <td>The pound-force has a metric counterpart, less...</td>\n",
              "      <td>What seldom used term of a unit of force equal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10569</th>\n",
              "      <td>665</td>\n",
              "      <td>sthène</td>\n",
              "      <td>Force</td>\n",
              "      <td>The pound-force has a metric counterpart, less...</td>\n",
              "      <td>What is the seldom used force unit equal to on...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10570 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       answer_start  ...                                           question\n",
              "0               177  ...  Which NFL team represented the AFC at Super Bo...\n",
              "1               249  ...  Which NFL team represented the NFC at Super Bo...\n",
              "2               403  ...                Where did Super Bowl 50 take place?\n",
              "3               177  ...                  Which NFL team won Super Bowl 50?\n",
              "4               488  ...  What color was used to emphasize the 50th anni...\n",
              "5               487  ...               What was the theme of Super Bowl 50?\n",
              "6               334  ...                   What day was the game played on?\n",
              "7               133  ...                         What is the AFC short for?\n",
              "8               487  ...               What was the theme of Super Bowl 50?\n",
              "9               133  ...                           What does AFC stand for?\n",
              "10              334  ...             What day was the Super Bowl played on?\n",
              "11              177  ...                             Who won Super Bowl 50?\n",
              "12              355  ...        What venue did Super Bowl 50 take place in?\n",
              "13              403  ...         What city did Super Bowl 50 take place in?\n",
              "14              693  ...  If Roman numerals were used, what would Super ...\n",
              "15              116  ...  Super Bowl 50 decided the NFL champion for wha...\n",
              "16              116  ...  What year did the Denver Broncos secure a Supe...\n",
              "17              403  ...         What city did Super Bowl 50 take place in?\n",
              "18              355  ...      What stadium did Super Bowl 50 take place in?\n",
              "19              267  ...        What was the final score of Super Bowl 50? \n",
              "20              334  ...  What month, day and year did Super Bowl 50 tak...\n",
              "21              116  ...                       What year was Super Bowl 50?\n",
              "22              177  ...                    What team was the AFC champion?\n",
              "23              249  ...                    What team was the NFC champion?\n",
              "24              177  ...                             Who won Super Bowl 50?\n",
              "25              116  ...  Super Bowl 50 determined the NFL champion for ...\n",
              "26              177  ...                      Which team won Super Bowl 50.\n",
              "27              403  ...                      Where was Super Bowl 50 held?\n",
              "28                0  ...          The name of the NFL championship game is?\n",
              "29              177  ...            What 2015 NFL team one the AFC playoff?\n",
              "...             ...  ...                                                ...\n",
              "10540           132  ...  What is used to calculate cross section area i...\n",
              "10541           132  ...            What are associated with normal forces?\n",
              "10542           113  ...  What includes pressure terms when calculating ...\n",
              "10543            77  ...  What is the force equivalent of torque compare...\n",
              "10544           346  ...  What would change the rotational inertia of a ...\n",
              "10545           375  ...  To calculate instant angular acceleration of a...\n",
              "10546           291  ...                   Where does centripetal force go?\n",
              "10547           346  ...  How do centripetal forces act in relation to v...\n",
              "10548           837  ...  What force changes an objects direction of tra...\n",
              "10549           829  ...        What is another word for centripetal force?\n",
              "10550           729  ...  What is resposible for speeding up or slowing ...\n",
              "10551           127  ...  What is the only form potential energy can cha...\n",
              "10552           138  ...  What is the only form kinetic energy can chang...\n",
              "10553           196  ...  What is preserved in a closed system of forces...\n",
              "10554           330  ...  What is the force between two locations relate...\n",
              "10555           434  ...  What is the force called rgarding a potential ...\n",
              "10556            58  ...             What is sometimes impossible to model?\n",
              "10557            81  ...  Why are some forces due to that are impossible...\n",
              "10558           252  ...  What do electrostatic gradiient potentials cre...\n",
              "10559           430  ...  Tension, compression, and drag are what kind o...\n",
              "10560           134  ...  In what treatment are nonconservative and cons...\n",
              "10561           188  ...   What changes macroscopic closed system energies?\n",
              "10562           188  ...      What is the exchange of heat associated with?\n",
              "10563           331  ...  What is the law of thermodynamics associated w...\n",
              "10564           361  ...      What makes energy changes in a closed system?\n",
              "10565            82  ...  What is the metric term less used than the New...\n",
              "10566           114  ...  What is the kilogram-force sometimes reffered ...\n",
              "10567           274  ...  What is a very seldom used unit of mass in the...\n",
              "10568           712  ...  What seldom used term of a unit of force equal...\n",
              "10569           665  ...  What is the seldom used force unit equal to on...\n",
              "\n",
              "[10570 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4qc0cW-J0tY",
        "colab_type": "text"
      },
      "source": [
        "### Convert strings to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaaUpdrs_S19",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "trainingData[\"question\"] = trainingData[\"question\"].str.lower()\n",
        "trainingData[\"article_title\"] = trainingData[\"article_title\"].str.lower()\n",
        "trainingData[\"paragraph_context\"] = trainingData[\"paragraph_context\"].str.lower()\n",
        "trainingData[\"answer_text\"] = trainingData[\"answer_text\"].str.lower()\n",
        "trainingData[\"answer_start\"] = pd.to_numeric(trainingData[\"answer_start\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-l8jQ_mb-Lje",
        "colab_type": "code",
        "outputId": "25c2fb37-1832-49fa-c6ac-27725a36ce6a",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title\n",
        "devData[\"question\"] = devData[\"question\"].str.lower()\n",
        "devData[\"article_title\"] = devData[\"article_title\"].str.lower()\n",
        "devData[\"paragraph_context\"] = devData[\"paragraph_context\"].str.lower()\n",
        "devData[\"answer_text\"] = devData[\"answer_text\"].str.lower()\n",
        "devData[\"answer_start\"] = pd.to_numeric(devData[\"answer_start\"])\n",
        "print(\"Finished loading dev data and lowering appropriate columns.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished loading dev data and lowering appropriate columns.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3o8XNwjRt4Ad",
        "colab": {}
      },
      "source": [
        "X_2_train = trainingData[[\"question\",\"paragraph_context\"]]\n",
        "Y_2_train = trainingData[\"answer_start\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjLYDGAUujy4",
        "colab_type": "text"
      },
      "source": [
        "### Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pkJ61xyU-LjU",
        "colab_type": "code",
        "outputId": "f22f79d9-bbac-4f18-dcf3-1eeff3d9e653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sys import getsizeof\n",
        "def vocabulary():\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "  data_frame = trainingData + devData\n",
        "  data_frame = data_frame.astype(\"str\")\n",
        "  phrases = []\n",
        "  for idx,row in data_frame.iterrows():\n",
        "    phrases.append(row[\"question\"])\n",
        "    phrases.append(row[\"paragraph_context\"])\n",
        "    phrases.append(row[\"article_title\"])\n",
        "  words = CountVectorizer().fit(phrases).get_feature_names()\n",
        "  return words\n",
        "def vocabularySize():\n",
        "  return len(vocabulary())\n",
        "def summaryStatistics(series):\n",
        "    numberOfWords = series.apply(lambda x: len(str(x).split(\" \")))\n",
        "    averageNumberOfWords = sum(numberOfWords) / len(numberOfWords)\n",
        "    return \"average: \" + str(averageNumberOfWords) + \"maximum: \" + str(max(numberOfWords)) + \" minimum: \" +str(min(numberOfWords))\n",
        "print(\"Size of vocabulary: \", vocabularySize())\n",
        "print(\"Words in each question: \",summaryStatistics(trainingData[\"question\"]))\n",
        "print(\"Words in each article title: \",summaryStatistics(trainingData[\"article_title\"]))\n",
        "print(\"Words in each context: \",summaryStatistics(trainingData[\"paragraph_context\"]))\n",
        "print(\"Words in each answer: \",summaryStatistics(trainingData[\"answer_text\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of vocabulary:  34236\n",
            "Words in each question:  average: 10.397504537723034maximum: 25601 minimum: 1\n",
            "Words in each article title:  average: 2.006621080149317maximum: 9 minimum: 1\n",
            "Words in each context:  average: 119.76870740533568maximum: 653 minimum: 20\n",
            "Words in each answer:  average: 3.1621822166919715maximum: 43 minimum: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8IUZ203W4qi",
        "colab_type": "text"
      },
      "source": [
        "####Get maximum ** possible** answer start.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnvr_TCH-Lkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "max_possible_answer_start = int(pd.concat((trainingData[\"answer_text\"],devData[\"answer_text\"])).str.len().max())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40XPLi7DW_Jd",
        "colab_type": "text"
      },
      "source": [
        "####Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGXSmR5M-Lk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ecPo0Jetse39"
      },
      "source": [
        "### Integer encode text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GCN8otUGse38"
      },
      "source": [
        "Used for manual encoding of text into integers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z19nkJI8iFmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strings = pd.concat((trainingData,devData)).drop(\"answer_start\",axis=1)\n",
        "strings = strings.values.flatten()\n",
        "textTokenizer = Tokenizer()\n",
        "textTokenizer.fit_on_texts(strings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iymfrGtadU0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get length of vocabulary.\n",
        "vocabulary_length = len(textTokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh5c5MeLe2Z1",
        "colab_type": "code",
        "outputId": "132fb7b2-a9d0-4c80-dbdc-33a6108704ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "# Get maximum length of all questions and contexts.\n",
        "max_length_questions = pd.concat((trainingData[\"question\"],devData[\"question\"])).str.split().len().max\n",
        "max_length_context = pd.concat((trainingData[\"paragraph_context\"],devData[\"paragraph_context\"])).str.len().max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-b7a943cfd50e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_length_questions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax_length_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"paragraph_context\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"paragraph_context\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'len'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqbzwlpakw8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "questionsTokenized_train = pad_sequences(np.array(textTokenizer.texts_to_sequences(trainingData[\"question\"])),maxlen=max_length_questions)\n",
        "contextTokenized_train = pad_sequences(np.array(textTokenizer.texts_to_sequences(trainingData[\"paragraph_context\"])),maxlen=max_length_context)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXVcBRqidB6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "questionsTokenized_dev = textTokenizer.texts_to_sequences(devData[\"question\"])\n",
        "contextTokenized_dev = textTokenizer.texts_to_sequences(devData[\"paragraph_context\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_ZjWkiReXH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad sequences.\n",
        "questionsTokenized_train = pad_sequences(questionsTokenized_train,maxlen=max_length_questions)\n",
        "contextTokenized_train = pad_sequences(contextTokenized_train,maxlen=max_length_context)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oq_sLBsSse3_"
      },
      "source": [
        "## Second neural network - non-recurrent/no transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IniJzW3lse3-"
      },
      "source": [
        "This neural network is used to generate answers from the questions and articles. It works by first reading the relevant article and using the question to find the answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V7fyv6DQse3V",
        "outputId": "c65b5ae6-734c-402a-a8cc-becdc1bfef98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "#Build the neural network.\n",
        "from math import log\n",
        "inputShape_second = X_2_train_num.shape[1:3]\n",
        "print(inputShape_second)\n",
        "answers_shape = Y_2_train_num.shape\n",
        "print(answers_shape[1])\n",
        "# Find the vocabulary length.\n",
        "vocabularyLength = np.concatenate((X_2_train_num,X_2_dev_num)).max() + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-056fa452021a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minputShape_second\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_2_train_num\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputShape_second\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0manswers_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_2_train_num\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_2_train_num' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Iv25QYbbse3Q",
        "outputId": "2b705537-b0fe-4934-ad3f-1ad0d6365054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "questions = Input(shape=(questionsTrain.shape[1],))\n",
        "context = Input(shape=(contextTrain.shape[1],))\n",
        "embedding_1 = Embedding(vocabularyLength,16)(questions)\n",
        "#answers_network.add(Dense(16))\n",
        "flatten_1 = Flatten()(embedding_1)\n",
        "hidden = Dense(16)(Dense(8)(flatten_1))\n",
        "hidden_2 = Dense(16)(hidden)\n",
        "hidden_3 = Dense(16)(hidden_2)\n",
        "dropout = Dropout(0.45)(hidden_3)\n",
        "output = Dense(answers_shape[1],activation='softmax')(dropout)\n",
        "answers_network = Model(inputs=[questions,context],outputs=output)\n",
        "answers_network.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7aff34f6a1d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestionsTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontextTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membedding_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabularyLength\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#answers_network.add(Dense(16))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mflatten_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'questionsTrain' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eTLaKjwyse3N",
        "colab": {}
      },
      "source": [
        "answers_network.compile(\"adam\",\"binary_crossentropy\",metrics=[f1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OSJyJ3qxse3L"
      },
      "source": [
        "#### Train the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IekQsi2Yse3J",
        "colab": {}
      },
      "source": [
        "answers_network_checkpoint = ModelCheckpoint('answers_network-non-rnn-best.h5', verbose=1, monitor='val_f1',save_best_only=True, mode='auto') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_tWTvWxSse3F",
        "colab": {}
      },
      "source": [
        "print(answers_network.metrics_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9hg2J0qBse3C",
        "colab": {}
      },
      "source": [
        "\n",
        "answers_network.fit(x=[questionsTrain,contextTrain],y=Y_2_train_num,callbacks=[answers_network_checkpoint],validation_split=0.2,verbose=True,epochs=9)\n",
        "#print(\"Weights: \",questions_article_model.get_weights())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LWDY4xhAse3A"
      },
      "source": [
        "#### Loading the model with best fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rEudSH2Ese29",
        "colab": {}
      },
      "source": [
        "answers_network.load_weights('answers_network-non-rnn-best.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ewsndbURse24",
        "colab": {}
      },
      "source": [
        "\n",
        "answers_network.evaluate([questionsDev,contextDev],Y_2_dev_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT2h3iAU-LlT",
        "colab_type": "text"
      },
      "source": [
        "## Transfer learning using Google's Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGUwjE61-LlU",
        "colab_type": "text"
      },
      "source": [
        "Our model has a very poor F1 score. Let's see if we can't build a better model. We'll use Google's BERT deep learning network, which is so good that the networks with SQuaD 2.0's highest recorded F1 score use it.  \n",
        "\n",
        "The basic idea behind BERT is this: Neural networks rely on numerical vectors. Similar sentences and phrases should produce similar vectors.\n",
        "\n",
        "\"It is not possible to train bidirectional models by simply conditioning each word on words before and after it. Doing this would allow the word that’s being predicted to indirectly see itself in a multi-layer model. To solve this, Google researchers used a straightforward technique of masking out some words in the input and condition each word bidirectionally in order to predict the masked words. This idea is not new, but BERT is the first technique where it was successfully used to pre-train a deep neural network.\" (packtpub.com)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doNFRjPqiBhM",
        "colab_type": "code",
        "outputId": "1aca603f-86bf-49f0-9b8c-563770e46977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "source": [
        "# @title Preparation\n",
        "!pip install -q keras-bert\n",
        "!wget -q https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!unzip -o uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUQ8UtquieFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title Environment\n",
        "import os\n",
        "\n",
        "pretrained_path = 'uncased_L-12_H-768_A-12'\n",
        "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
        "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
        "vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
        "\n",
        "# TF_KERAS must be added to environment variables in order to use TPU\n",
        "os.environ['TF_KERAS'] = '1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exDvuSwPevQP",
        "colab_type": "code",
        "outputId": "5129ccd8-c0a8-4f15-b500-450e61711505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# @title Initialize TPU Strategy\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras_bert import get_custom_objects\n",
        "\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        "tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "strategy = tf.contrib.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0828 21:53:01.076310 139887942354816 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVTPNxOyj4HJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title Load Basic Model\n",
        "import codecs\n",
        "from keras_bert import load_trained_model_from_checkpoint\n",
        "\n",
        "token_dict = {}\n",
        "with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
        "    for line in reader:\n",
        "        token = line.strip()\n",
        "        token_dict[token] = len(token_dict)\n",
        "\n",
        "model = load_trained_model_from_checkpoint(config_path, checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xioN-O_vtztC",
        "colab_type": "code",
        "outputId": "1d22afb7-e257-43b9-b6dd-e49af47a664c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "# @title Tokenization\n",
        "import numpy as np\n",
        "from keras_bert import Tokenizer\n",
        "tokenizer = Tokenizer(token_dict)\n",
        "def tokenize(text):\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  indices, segments = tokenizer.encode(first=text, max_len=512)\n",
        "  return indices,segments\n",
        "def feature_extraction(texts):\n",
        "  return_values = []\n",
        "  for text_ in texts:\n",
        "    try:\n",
        "      text_.split(\" \")\n",
        "    except AttributeError as e:\n",
        "      raise TypeError(\"Expected array of strings.\")\n",
        "    try:\n",
        "      indices,segments = tokenize(text_)\n",
        "      predicts = model.predict([np.array([indices] * 8), np.array([segments] * 8)])[0]\n",
        "      return_values.append(predicts)\n",
        "    except ValueError as v:\n",
        "      print(v)\n",
        "  return_values = np.array(return_values)\n",
        "  return return_values\n",
        "text = \"She sells seashells by the seashore.\"\n",
        "text_array = np.asarray([text,\"She does not sell seashells by the seashore\"],dtype='object')\n",
        "print(text_array.dtype)\n",
        "print(\"text\")\n",
        "print(feature_extraction(text_array).shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "object\n",
            "text\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-eeb74f55e110>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-57-eeb74f55e110>\u001b[0m in \u001b[0;36mfeature_extraction\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mpredicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0mreturn_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1076\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m           callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrCQmdqAlU4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_generator(dataset,batch_size):\n",
        "  while True:\n",
        "    batch = dataset.sample(n=batch_size,replace=True)\n",
        "    try:\n",
        "      batch_features = feature_extraction(batch[\"question\"].values)\n",
        "    except ValueError as v:\n",
        "      print(\"Oops, I'm getting a ValueError for batch_features.\")\n",
        "      print(v)\n",
        "    try:\n",
        "      batch_targets = batch[\"answer_start\"]\n",
        "    except ValueError as v:\n",
        "      print(\"Oops, I'm getting a ValueError for batch_targets.\")\n",
        "      print(v)\n",
        "    \n",
        "    yield batch_features,batch_targets\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFccttuClo7Q",
        "colab_type": "code",
        "outputId": "39987f5a-8ad4-409a-b14a-5d7a169c9cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "test_dataset = pd.DataFrame({\"question\":[\"Does she sell seashells by the seashore\"],\"paragraph_context\":[\"She sells seashells by the seashore\"],\"answer_start\":[0]})\n",
        "test_dataset"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>paragraph_context</th>\n",
              "      <th>answer_start</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Does she sell seashells by the seashore</td>\n",
              "      <td>She sells seashells by the seashore</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  question  ... answer_start\n",
              "0  Does she sell seashells by the seashore  ...            0\n",
              "\n",
              "[1 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC8T2AXRX0Mn",
        "colab_type": "code",
        "outputId": "a8342a50-4419-4c85-8d19-7e3040914f46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "for x,y in batch_generator(test_dataset,2):\n",
        "  print(x.shape)\n",
        "  print(y.shape)\n",
        "  assert x.shape[0] == y.shape[0], \"Shape mismatch.\"\n",
        "  print(x.dtype)\n",
        "  print(x)\n",
        "  print(y)\n",
        "  break"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (512, 768)\n",
            "Prediction shape:  (512, 768)\n",
            "Return values shape:  (2, 512, 768)\n",
            "(2, 512, 768)\n",
            "(2,)\n",
            "float32\n",
            "[[[-0.31885183 -0.12924516 -0.18322109 ... -0.35949844  0.18972889\n",
            "   -0.10933438]\n",
            "  [ 0.311414    0.17972124 -0.10798444 ... -0.11876195  0.56598294\n",
            "   -0.31934875]\n",
            "  [ 0.5496158  -1.0750685  -0.24597827 ... -0.9492761   0.16425355\n",
            "   -0.2893064 ]\n",
            "  ...\n",
            "  [ 0.29522124 -0.09924655  0.21650063 ... -0.04205173  0.06311297\n",
            "   -0.4185968 ]\n",
            "  [ 0.1601033  -0.13200733  0.1676978  ...  0.00439339  0.05115967\n",
            "   -0.49891245]\n",
            "  [ 0.05326451 -0.19191569  0.1559972  ... -0.06486911  0.10209841\n",
            "   -0.3616868 ]]\n",
            "\n",
            " [[-0.31885183 -0.12924516 -0.18322109 ... -0.35949844  0.18972889\n",
            "   -0.10933438]\n",
            "  [ 0.311414    0.17972124 -0.10798444 ... -0.11876195  0.56598294\n",
            "   -0.31934875]\n",
            "  [ 0.5496158  -1.0750685  -0.24597827 ... -0.9492761   0.16425355\n",
            "   -0.2893064 ]\n",
            "  ...\n",
            "  [ 0.29522124 -0.09924655  0.21650063 ... -0.04205173  0.06311297\n",
            "   -0.4185968 ]\n",
            "  [ 0.1601033  -0.13200733  0.1676978  ...  0.00439339  0.05115967\n",
            "   -0.49891245]\n",
            "  [ 0.05326451 -0.19191569  0.1559972  ... -0.06486911  0.10209841\n",
            "   -0.3616868 ]]]\n",
            "0    0\n",
            "0    0\n",
            "Name: answer_start, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRNnqt-8eXyJ",
        "colab_type": "code",
        "outputId": "42134ca2-c5d7-4047-cf05-01d3311f5e36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "#@title Model Summary\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      [(None, 512)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding [(None, 512, 768), ( 23440896    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, 512, 768)     1536        Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, 512, 768)     0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, 512, 768)     393216      Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, 512, 768)     0           Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, 512, 768)     1536        Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 512, 768)     2362368     Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 512, 768)     0           Embedding-Norm[0][0]             \n",
            "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-3-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-4-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-5-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-6-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-7-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-8-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-9-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 512, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 512, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedFor (None, 512, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout  (None, 512, 768)     0           Encoder-10-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add (None, 512, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (La (None, 512, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 512, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 512, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedFor (None, 512, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout  (None, 512, 768)     0           Encoder-11-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add (None, 512, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (La (None, 512, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 512, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 512, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedFor (None, 512, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout  (None, 512, 768)     0           Encoder-12-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add (None, 512, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (La (None, 512, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
            "==================================================================================================\n",
            "Total params: 108,891,648\n",
            "Trainable params: 0\n",
            "Non-trainable params: 108,891,648\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEKhgXry-Lle",
        "colab_type": "code",
        "outputId": "eec6b02e-4d7a-4e8c-f847-e03a4e678ab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#@title Incorporate model into answers network.\n",
        "answers_network = Sequential()\n",
        "answers_network.add(Dense(32,input_shape=(512,768)))\n",
        "answers_network.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512, 32)           24608     \n",
            "=================================================================\n",
            "Total params: 24,608\n",
            "Trainable params: 24,608\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fauCafTdkzMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_2_train = trainingData[[\"question\",\"paragraph_context\",\"answer_start\"]]\n",
        "nn_2_cross_validation = crossValidationData[[\"question\",\"paragraph_context\",\"answer_start\"]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7MAxmnKlK9z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn_2_train_features = feature_extraction(nn_2_train)\n",
        "nn_2_cross_validation_features = feature_extraction(nn_2_cross_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDLyZ09mzjD5",
        "colab_type": "code",
        "outputId": "1f6d737c-b78a-45fd-e7a3-2a69e0e0fb32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "#@title Fitting neural network\n",
        "print(\"Done creating features.\")\n",
        "answers_network.compile(\"rmsprop\",\"categorical_crossentropy\")\n",
        "answers_network_checkpoint = ModelCheckpoint('answers_network-rnn-best.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')\n",
        "answers_network.fit(x=callbacks=[answers_network_checkpoint])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done creating features.\n",
            "Epoch 1/8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-5f523b571a24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0manswers_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rmsprop\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0manswers_network_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'answers_network-rnn-best.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0manswers_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn_2_train_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn_2_cross_validation_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0manswers_network_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator, mode)\u001b[0m\n\u001b[1;32m    360\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0;34m'Keras requires a thread-safe generator when '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             '`use_multiprocessing=False, workers > 1`. ')\n\u001b[0;32m--> 918\u001b[0;31m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m    826\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m   \"\"\"\n\u001b[0;32m--> 828\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-9ea6576c93c6>\u001b[0m in \u001b[0;36mbatch_generator\u001b[0;34m(dataset, batch_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0mbatch_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Oops, I'm getting a ValueError for batch_features.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-c07f53aad9b4>\u001b[0m in \u001b[0;36mfeature_extraction\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mpredicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction shape: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mreturn_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1076\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m           callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3287\u001b[0m         \u001b[0mfeed_symbols\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_symbols\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m         session != self._session):\n\u001b[0;32m-> 3289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   3220\u001b[0m       \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3221\u001b[0m     \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3222\u001b[0;31m     \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3223\u001b[0m     \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3224\u001b[0m     \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \"\"\"\n\u001b[1;32m   1488\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1489\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1444\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m         self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1446\u001b[0;31m             session._session, options_ptr)\n\u001b[0m\u001b[1;32m   1447\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Tensor Input-Token:0, specified in either feed_devices or fetch_devices was not found in the Graph"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g3VSE-Paicq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}