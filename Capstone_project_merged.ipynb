{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone_project_merged.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "ecPo0Jetse39",
        "oq_sLBsSse3_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoIQFdjR-Lid",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDXUu5iW-Lij",
        "colab_type": "text"
      },
      "source": [
        "Load Python modules."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGcmXwG--Lio",
        "colab_type": "code",
        "outputId": "85be2b44-89ae-416d-c5ac-56faf6d71b82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "!pip install pyspellchecker\n",
        "\n",
        "from spellchecker import SpellChecker\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tensorflow.python.client import device_lib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding,Dropout,Lambda,Dense,Input,LSTM,Concatenate,Flatten,Add,Reshape,GlobalAveragePooling1D,GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import sys\n",
        "assert sys.version_info[0] >= 3\n",
        "print(tf.VERSION)\n",
        "print(\"Set up!\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspellchecker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/4a/9d85c7ddeb8761ab71ef064d2ac1b1af6cae728367f5c4f74a5d1adc1360/pyspellchecker-0.4.0-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 3.4MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.4.0\n",
            "1.13.1\n",
            "Set up!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXFuFons-LjA",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqjrxOes-LjD",
        "colab_type": "text"
      },
      "source": [
        "For the preprocessing step, we will create two dictionaries. One will be used to map questions to articles, while the other will be used to map questions and the contents of the articles to the answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8UbZDe--LjG",
        "colab_type": "text"
      },
      "source": [
        "### Loading JSON datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I79-hb5dCBfy",
        "colab_type": "code",
        "outputId": "39ba85dc-7458-4201-c70e-2cc7ede81df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!wget https://github.com/moonman239/Capstone-project/raw/master/data.zip -O data.zip\n",
        "!unzip data.zip\n",
        "assert os.path.isfile(\"train-v1.1.json\"),\"Non-existent file\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-11 19:28:03--  https://github.com/moonman239/Capstone-project/raw/master/data.zip\n",
            "Resolving github.com (github.com)... 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/moonman239/Capstone-project/master/data.zip [following]\n",
            "--2019-06-11 19:28:04--  https://raw.githubusercontent.com/moonman239/Capstone-project/master/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9048060 (8.6M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   8.63M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-06-11 19:28:05 (77.9 MB/s) - ‘data.zip’ saved [9048060/9048060]\n",
            "\n",
            "Archive:  data.zip\n",
            "  inflating: dev-v1.1.json           \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._dev-v1.1.json  \n",
            "  inflating: train-v1.1.json         \n",
            "  inflating: __MACOSX/._train-v1.1.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fgU382EF26d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import re\n",
        "regex = re.compile(r'\\W+')\n",
        "def readFile(filename):\n",
        "  with open(filename) as file:\n",
        "    fields = []\n",
        "    JSON = json.loads(file.read())\n",
        "    for article in JSON[\"data\"]:\n",
        "      articleTitle = article[\"title\"]\n",
        "      for paragraph in article[\"paragraphs\"]:\n",
        "        paragraphContext = paragraph[\"context\"]\n",
        "        for qas in paragraph[\"qas\"]:\n",
        "          question = qas[\"question\"]\n",
        "          for answer in qas[\"answers\"]:\n",
        "            fields.append({\"question\":question,\"answer_text\":answer[\"text\"],\"answer_start\":answer[\"answer_start\"],\"paragraph_context\":paragraphContext,\"article_title\":articleTitle})\n",
        "  fields = pd.DataFrame(fields)\n",
        "  fields[\"question\"] = fields[\"question\"].str.replace(regex,\" \")\n",
        "  assert not (fields[\"question\"].str.contains(\"catalanswhat\").any())\n",
        "  fields[\"paragraph_context\"] = fields[\"paragraph_context\"].str.replace(regex,\" \")\n",
        "  fields[\"answer_text\"] = fields[\"answer_text\"].str.replace(regex,\" \")\n",
        "  assert not (fields[\"paragraph_context\"].str.contains(\"catalanswhat\").any())\n",
        "  fields[\"article_title\"] = fields[\"article_title\"].str.replace(\"_\",\" \")\n",
        "  assert not (fields[\"article_title\"].str.contains(\"catalanswhat\").any())\n",
        "  return fields"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1Ql0r8fOpCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainingData = readFile(\"train-v1.1.json\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XufEvRe0ap_R",
        "colab_type": "code",
        "outputId": "3711a260-7bb1-4507-a1b4-035d40da40bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2989
        }
      },
      "source": [
        "trainingData"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer_start</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>article_title</th>\n",
              "      <th>paragraph_context</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>515</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>Architecturally the school has a Catholic char...</td>\n",
              "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>188</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>Architecturally the school has a Catholic char...</td>\n",
              "      <td>What is in front of the Notre Dame Main Building</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>279</td>\n",
              "      <td>the Main Building</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>Architecturally the school has a Catholic char...</td>\n",
              "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>381</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>Architecturally the school has a Catholic char...</td>\n",
              "      <td>What is the Grotto at Notre Dame</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>92</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>Architecturally the school has a Catholic char...</td>\n",
              "      <td>What sits on top of the Main Building at Notre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>248</td>\n",
              "      <td>September 1876</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>As at most other universities Notre Dame s stu...</td>\n",
              "      <td>When did the Scholastic Magazine of Notre dame...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>441</td>\n",
              "      <td>twice</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>As at most other universities Notre Dame s stu...</td>\n",
              "      <td>How often is Notre Dame s the Juggler published</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>598</td>\n",
              "      <td>The Observer</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>As at most other universities Notre Dame s stu...</td>\n",
              "      <td>What is the daily student paper at Notre Dame ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>126</td>\n",
              "      <td>three</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>As at most other universities Notre Dame s stu...</td>\n",
              "      <td>How many student news papers are found at Notr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>908</td>\n",
              "      <td>1987</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>As at most other universities Notre Dame s stu...</td>\n",
              "      <td>In what year did the student paper Common Sens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>119</td>\n",
              "      <td>Rome</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university is the major seat of the Congre...</td>\n",
              "      <td>Where is the headquarters of the Congregation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>145</td>\n",
              "      <td>Moreau Seminary</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university is the major seat of the Congre...</td>\n",
              "      <td>What is the primary seminary of the Congregati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>234</td>\n",
              "      <td>Old College</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university is the major seat of the Congre...</td>\n",
              "      <td>What is the oldest structure at Notre Dame</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>356</td>\n",
              "      <td>Retired priests and brothers</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university is the major seat of the Congre...</td>\n",
              "      <td>What individuals live at Fatima House at Notre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>675</td>\n",
              "      <td>Buechner Prize for Preaching</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university is the major seat of the Congre...</td>\n",
              "      <td>Which prize did Frederick Buechner create</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>487</td>\n",
              "      <td>eight</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The College of Engineering was established in ...</td>\n",
              "      <td>How many BS level degrees are offered in the C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>46</td>\n",
              "      <td>1920</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The College of Engineering was established in ...</td>\n",
              "      <td>In what year was the College of Engineering at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>126</td>\n",
              "      <td>the College of Science</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The College of Engineering was established in ...</td>\n",
              "      <td>Before the creation of the College of Engineer...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>271</td>\n",
              "      <td>five</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The College of Engineering was established in ...</td>\n",
              "      <td>How many departments are within the Stinson Re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>155</td>\n",
              "      <td>the 1870s</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The College of Engineering was established in ...</td>\n",
              "      <td>The College of Science began to offer civil en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>496</td>\n",
              "      <td>Learning Resource Center</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>All of Notre Dame s undergraduate students are...</td>\n",
              "      <td>What entity provides help with the management ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>68</td>\n",
              "      <td>five</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>All of Notre Dame s undergraduate students are...</td>\n",
              "      <td>How many colleges for undergraduates are at No...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>155</td>\n",
              "      <td>The First Year of Studies program</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>All of Notre Dame s undergraduate students are...</td>\n",
              "      <td>What was created at Notre Dame in 1962 to assi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>647</td>\n",
              "      <td>U S News World Report</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>All of Notre Dame s undergraduate students are...</td>\n",
              "      <td>Which organization declared the First Year of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>358</td>\n",
              "      <td>1924</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university first offered graduate degrees ...</td>\n",
              "      <td>The granting of Doctorate degrees first occurr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>624</td>\n",
              "      <td>Master of Divinity</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university first offered graduate degrees ...</td>\n",
              "      <td>What type of degree is an M Div</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1163</td>\n",
              "      <td>Alliance for Catholic Education</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university first offered graduate degrees ...</td>\n",
              "      <td>Which program at Notre Dame offers a Master of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>92</td>\n",
              "      <td>1854</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university first offered graduate degrees ...</td>\n",
              "      <td>In what year was a Master of Arts course first...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>757</td>\n",
              "      <td>Department of Pre Professional Studies</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The university first offered graduate degrees ...</td>\n",
              "      <td>Which department at Notre Dame is the only one...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>4</td>\n",
              "      <td>Joan B Kroc Institute for International Peace ...</td>\n",
              "      <td>University of Notre Dame</td>\n",
              "      <td>The Joan B Kroc Institute for International Pe...</td>\n",
              "      <td>What institute at Notre Dame studies the reaso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87569</th>\n",
              "      <td>209</td>\n",
              "      <td>Gyaneshwar</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Sikhism is practiced primarily in Gurudwara at...</td>\n",
              "      <td>Where can a temple of the Jain faith be found</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87570</th>\n",
              "      <td>355</td>\n",
              "      <td>300</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Sikhism is practiced primarily in Gurudwara at...</td>\n",
              "      <td>Kathmandu valley is home to about how many Bah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87571</th>\n",
              "      <td>427</td>\n",
              "      <td>Shantinagar Baneshwor</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Sikhism is practiced primarily in Gurudwara at...</td>\n",
              "      <td>Where is the Baha i national office located in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87572</th>\n",
              "      <td>633</td>\n",
              "      <td>4 2</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Sikhism is practiced primarily in Gurudwara at...</td>\n",
              "      <td>About what percentage of the Nepali population...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87573</th>\n",
              "      <td>728</td>\n",
              "      <td>170</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Sikhism is practiced primarily in Gurudwara at...</td>\n",
              "      <td>About how many Christian houses of worship exi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87574</th>\n",
              "      <td>46</td>\n",
              "      <td>Tribhuwan</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Institute of Medicine the central college of T...</td>\n",
              "      <td>Of what university is the Institute of Medicin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87575</th>\n",
              "      <td>123</td>\n",
              "      <td>Maharajgunj</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Institute of Medicine the central college of T...</td>\n",
              "      <td>In what part of Kathmandu is the Institute of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87576</th>\n",
              "      <td>219</td>\n",
              "      <td>1978</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Institute of Medicine the central college of T...</td>\n",
              "      <td>When did the Institute of Medicine begin to of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87577</th>\n",
              "      <td>425</td>\n",
              "      <td>Kathmandu University School of Medical Sciences</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Institute of Medicine the central college of T...</td>\n",
              "      <td>What does KUSMS stand for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87578</th>\n",
              "      <td>377</td>\n",
              "      <td>National Academy of Medical Sciences</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Institute of Medicine the central college of T...</td>\n",
              "      <td>What institution of tertiary education is know...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87579</th>\n",
              "      <td>0</td>\n",
              "      <td>Football</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Football and Cricket are the most popular spor...</td>\n",
              "      <td>Along with cricket what sport is highly popula...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87580</th>\n",
              "      <td>160</td>\n",
              "      <td>All Nepal Football Association</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Football and Cricket are the most popular spor...</td>\n",
              "      <td>What body oversees soccer in Nepal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87581</th>\n",
              "      <td>498</td>\n",
              "      <td>25 000</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Football and Cricket are the most popular spor...</td>\n",
              "      <td>How many people can fit in Dasarath Rangasala ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87582</th>\n",
              "      <td>430</td>\n",
              "      <td>Tripureshwor</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Football and Cricket are the most popular spor...</td>\n",
              "      <td>In what part of Kathmandu is Dasarath Rangasal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87583</th>\n",
              "      <td>628</td>\n",
              "      <td>Chinese</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Football and Cricket are the most popular spor...</td>\n",
              "      <td>Who assisted Nepal in renovating Dasarath Rang...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87584</th>\n",
              "      <td>54</td>\n",
              "      <td>17 182</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The total length of roads in Nepal is recorded...</td>\n",
              "      <td>As of 2004 how many kilometers of road existed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87585</th>\n",
              "      <td>289</td>\n",
              "      <td>hilly terrain</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The total length of roads in Nepal is recorded...</td>\n",
              "      <td>Why is travel in Kathmandu mainly via automobi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87586</th>\n",
              "      <td>500</td>\n",
              "      <td>BP</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The total length of roads in Nepal is recorded...</td>\n",
              "      <td>What highway connecting Kathmandu to elsewhere...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87587</th>\n",
              "      <td>457</td>\n",
              "      <td>west</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The total length of roads in Nepal is recorded...</td>\n",
              "      <td>In what direction out of Kathmandu does the Pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87588</th>\n",
              "      <td>466</td>\n",
              "      <td>Araniko</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The total length of roads in Nepal is recorded...</td>\n",
              "      <td>If one wished to travel north out of Kathmandu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87589</th>\n",
              "      <td>71</td>\n",
              "      <td>Tribhuvan International Airport</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The main international airport serving Kathman...</td>\n",
              "      <td>What is Nepal s primary airport for internatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87590</th>\n",
              "      <td>134</td>\n",
              "      <td>6</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The main international airport serving Kathman...</td>\n",
              "      <td>Starting in the center of Kathmandu how many k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87591</th>\n",
              "      <td>297</td>\n",
              "      <td>22</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The main international airport serving Kathman...</td>\n",
              "      <td>How many airlines use Tribhuvan International ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87592</th>\n",
              "      <td>698</td>\n",
              "      <td>Amsterdam</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The main international airport serving Kathman...</td>\n",
              "      <td>From what city does Arkefly offer nonstop flig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87593</th>\n",
              "      <td>734</td>\n",
              "      <td>Turkish Airlines</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>The main international airport serving Kathman...</td>\n",
              "      <td>Who operates flights between Kathmandu and Ist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87594</th>\n",
              "      <td>229</td>\n",
              "      <td>Oregon</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Kathmandu Metropolitan City KMC in order to pr...</td>\n",
              "      <td>In what US state did Kathmandu first establish...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87595</th>\n",
              "      <td>414</td>\n",
              "      <td>Rangoon</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Kathmandu Metropolitan City KMC in order to pr...</td>\n",
              "      <td>What was Yangon previously known as</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87596</th>\n",
              "      <td>476</td>\n",
              "      <td>Minsk</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Kathmandu Metropolitan City KMC in order to pr...</td>\n",
              "      <td>With what Belorussian city does Kathmandu have...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87597</th>\n",
              "      <td>199</td>\n",
              "      <td>1975</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Kathmandu Metropolitan City KMC in order to pr...</td>\n",
              "      <td>In what year did Kathmandu create its initial ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87598</th>\n",
              "      <td>0</td>\n",
              "      <td>Kathmandu Metropolitan City</td>\n",
              "      <td>Kathmandu</td>\n",
              "      <td>Kathmandu Metropolitan City KMC in order to pr...</td>\n",
              "      <td>What is KMC an initialism of</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>87599 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       answer_start  ...                                           question\n",
              "0               515  ...  To whom did the Virgin Mary allegedly appear i...\n",
              "1               188  ...  What is in front of the Notre Dame Main Building \n",
              "2               279  ...  The Basilica of the Sacred heart at Notre Dame...\n",
              "3               381  ...                  What is the Grotto at Notre Dame \n",
              "4                92  ...  What sits on top of the Main Building at Notre...\n",
              "5               248  ...  When did the Scholastic Magazine of Notre dame...\n",
              "6               441  ...   How often is Notre Dame s the Juggler published \n",
              "7               598  ...  What is the daily student paper at Notre Dame ...\n",
              "8               126  ...  How many student news papers are found at Notr...\n",
              "9               908  ...  In what year did the student paper Common Sens...\n",
              "10              119  ...  Where is the headquarters of the Congregation ...\n",
              "11              145  ...  What is the primary seminary of the Congregati...\n",
              "12              234  ...        What is the oldest structure at Notre Dame \n",
              "13              356  ...  What individuals live at Fatima House at Notre...\n",
              "14              675  ...         Which prize did Frederick Buechner create \n",
              "15              487  ...  How many BS level degrees are offered in the C...\n",
              "16               46  ...  In what year was the College of Engineering at...\n",
              "17              126  ...  Before the creation of the College of Engineer...\n",
              "18              271  ...  How many departments are within the Stinson Re...\n",
              "19              155  ...  The College of Science began to offer civil en...\n",
              "20              496  ...  What entity provides help with the management ...\n",
              "21               68  ...  How many colleges for undergraduates are at No...\n",
              "22              155  ...  What was created at Notre Dame in 1962 to assi...\n",
              "23              647  ...  Which organization declared the First Year of ...\n",
              "24              358  ...  The granting of Doctorate degrees first occurr...\n",
              "25              624  ...                   What type of degree is an M Div \n",
              "26             1163  ...  Which program at Notre Dame offers a Master of...\n",
              "27               92  ...  In what year was a Master of Arts course first...\n",
              "28              757  ...  Which department at Notre Dame is the only one...\n",
              "29                4  ...  What institute at Notre Dame studies the reaso...\n",
              "...             ...  ...                                                ...\n",
              "87569           209  ...     Where can a temple of the Jain faith be found \n",
              "87570           355  ...  Kathmandu valley is home to about how many Bah...\n",
              "87571           427  ...  Where is the Baha i national office located in...\n",
              "87572           633  ...  About what percentage of the Nepali population...\n",
              "87573           728  ...  About how many Christian houses of worship exi...\n",
              "87574            46  ...  Of what university is the Institute of Medicin...\n",
              "87575           123  ...  In what part of Kathmandu is the Institute of ...\n",
              "87576           219  ...  When did the Institute of Medicine begin to of...\n",
              "87577           425  ...                         What does KUSMS stand for \n",
              "87578           377  ...  What institution of tertiary education is know...\n",
              "87579             0  ...  Along with cricket what sport is highly popula...\n",
              "87580           160  ...                What body oversees soccer in Nepal \n",
              "87581           498  ...  How many people can fit in Dasarath Rangasala ...\n",
              "87582           430  ...  In what part of Kathmandu is Dasarath Rangasal...\n",
              "87583           628  ...  Who assisted Nepal in renovating Dasarath Rang...\n",
              "87584            54  ...  As of 2004 how many kilometers of road existed...\n",
              "87585           289  ...  Why is travel in Kathmandu mainly via automobi...\n",
              "87586           500  ...  What highway connecting Kathmandu to elsewhere...\n",
              "87587           457  ...  In what direction out of Kathmandu does the Pr...\n",
              "87588           466  ...  If one wished to travel north out of Kathmandu...\n",
              "87589            71  ...  What is Nepal s primary airport for internatio...\n",
              "87590           134  ...  Starting in the center of Kathmandu how many k...\n",
              "87591           297  ...  How many airlines use Tribhuvan International ...\n",
              "87592           698  ...  From what city does Arkefly offer nonstop flig...\n",
              "87593           734  ...  Who operates flights between Kathmandu and Ist...\n",
              "87594           229  ...  In what US state did Kathmandu first establish...\n",
              "87595           414  ...               What was Yangon previously known as \n",
              "87596           476  ...  With what Belorussian city does Kathmandu have...\n",
              "87597           199  ...  In what year did Kathmandu create its initial ...\n",
              "87598             0  ...                      What is KMC an initialism of \n",
              "\n",
              "[87599 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaaUpdrs_S19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "trainingData[\"question\"] = trainingData[\"question\"].str.lower()\n",
        "trainingData[\"article_title\"] = trainingData[\"article_title\"].str.lower()\n",
        "trainingData[\"paragraph_context\"] = trainingData[\"paragraph_context\"].str.lower()\n",
        "trainingData[\"answer_text\"] = trainingData[\"answer_text\"].str.lower()\n",
        "trainingData[\"answer_start\"] = pd.to_numeric(trainingData[\"answer_start\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-l8jQ_mb-Lje",
        "colab_type": "code",
        "outputId": "59e7839d-7470-4bda-ed64-f86315269eca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "devData = readFile(\"dev-v1.1.json\")\n",
        "devData[\"question\"] = devData[\"question\"].str.lower()\n",
        "devData[\"article_title\"] = devData[\"article_title\"].str.lower()\n",
        "devData[\"paragraph_context\"] = devData[\"paragraph_context\"].str.lower()\n",
        "devData[\"answer_text\"] = devData[\"answer_text\"].str.lower()\n",
        "devData[\"answer_start\"] = pd.to_numeric(devData[\"answer_start\"])\n",
        "print(\"Finished loading dev data and lowering appropriate columns.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished loading dev data and lowering appropriate columns.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbBs-K8Duczl",
        "colab_type": "text"
      },
      "source": [
        "#### Spell- and grammar-checking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvx14MapuVub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def checkMisspellings(sentences):\n",
        "  spell_checker = SpellChecker(distance=1)\n",
        "  words = sentences.str.split().values\n",
        "  unknown = np.vectorize(spell_checker.unknown)\n",
        "  misspelledWords = unknown(words)\n",
        "  def correctionFn(_list):\n",
        "    try:\n",
        "      corrections = []\n",
        "      for word in _list:\n",
        "        assert isinstance(word,str),\"String expected.\"\n",
        "        corrections.append(spell_checker.correction(word))\n",
        "      return corrections\n",
        "    except:\n",
        "      import sys\n",
        "      print(sys.exc_info())\n",
        "  correctionFn = np.vectorize(correctionFn,otypes=[list])\n",
        "  corrections = correctionFn(np.array([\"hello\",\"me\"]))\n",
        "  #words_with_corrections = np.hstack((misspelledWords,corrections))\n",
        "  return "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kThOOa3DdCte",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3723
        },
        "outputId": "36195fe6-66b2-45cd-efd3-f07b4e6799eb"
      },
      "source": [
        "\n",
        "test = pd.Series(trainingData[\"answer_text\"][0:2])\n",
        "checkMisspellings(test)\n",
        "from cProfile import run\n",
        "testResults = run('checkMisspellings(test)')\n",
        "print(testResults)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         121467 function calls (121203 primitive calls) in 0.171 seconds\n",
            "\n",
            "   Ordered by: standard name\n",
            "\n",
            "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
            "        5    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:997(_handle_fromlist)\n",
            "        1    0.000    0.000    0.169    0.169 <ipython-input-154-085cbcb8bb29>:1(checkMisspellings)\n",
            "        2    0.000    0.000    0.000    0.000 <ipython-input-154-085cbcb8bb29>:6(correctionFn)\n",
            "        1    0.002    0.002    0.171    0.171 <string>:1(<module>)\n",
            "        1    0.000    0.000    0.079    0.079 __init__.py:302(loads)\n",
            "        1    0.000    0.000    0.000    0.000 __init__.py:517(__init__)\n",
            "        2    0.000    0.000    0.013    0.006 __init__.py:586(update)\n",
            "        1    0.000    0.000    0.000    0.000 _bootlocale.py:23(getpreferredencoding)\n",
            "        2    0.000    0.000    0.000    0.000 _compression.py:12(_check_not_closed)\n",
            "        1    0.000    0.000    0.000    0.000 _compression.py:150(tell)\n",
            "        1    0.000    0.000    0.000    0.000 _compression.py:36(readable)\n",
            "        1    0.000    0.000    0.000    0.000 _compression.py:39(__init__)\n",
            "        1    0.000    0.000    0.000    0.000 _compression.py:59(close)\n",
            "        2    0.000    0.000    0.000    0.000 _dtype.py:319(_name_get)\n",
            "        4    0.000    0.000    0.000    0.000 _internal.py:886(npy_ctypes_check)\n",
            "        7    0.000    0.000    0.000    0.000 _weakrefset.py:70(__contains__)\n",
            "        5    0.000    0.000    0.000    0.000 abc.py:180(__instancecheck__)\n",
            "        1    0.000    0.000    0.000    0.000 arrays.py:7(extract_array)\n",
            "        1    0.000    0.000    0.000    0.000 base.py:5318(ensure_index)\n",
            "        7    0.000    0.000    0.000    0.000 base.py:75(is_dtype)\n",
            "        2    0.000    0.000    0.000    0.000 blocks.py:161(external_values)\n",
            "        1    0.000    0.000    0.000    0.000 blocks.py:195(mgr_locs)\n",
            "        1    0.000    0.000    0.000    0.000 blocks.py:199(mgr_locs)\n",
            "        1    0.000    0.000    0.000    0.000 blocks.py:2626(__init__)\n",
            "        1    0.000    0.000    0.000    0.000 blocks.py:3034(get_block_type)\n",
            "        1    0.000    0.000    0.000    0.000 blocks.py:3080(make_block)\n",
            "        1    0.000    0.000    0.000    0.000 blocks.py:78(__init__)\n",
            "        1    0.000    0.000    0.000    0.000 blocks.py:89(_check_ndim)\n",
            "        1    0.000    0.000    0.000    0.000 cast.py:1218(construct_1d_ndarray_preserving_na)\n",
            "        1    0.000    0.000    0.000    0.000 cast.py:832(maybe_castable)\n",
            "        1    0.000    0.000    0.000    0.000 cast.py:846(maybe_infer_to_datetimelike)\n",
            "        1    0.000    0.000    0.000    0.000 cast.py:953(maybe_cast_to_datetime)\n",
            "        1    0.000    0.000    0.000    0.000 codecs.py:259(__init__)\n",
            "        1    0.000    0.000    0.000    0.000 codecs.py:308(__init__)\n",
            "        1    0.000    0.000    0.001    0.001 codecs.py:318(decode)\n",
            "        3    0.000    0.000    0.000    0.000 common.py:117(classes)\n",
            "        3    0.000    0.000    0.000    0.000 common.py:119(<lambda>)\n",
            "        1    0.000    0.000    0.000    0.000 common.py:122(classes_and_not_datetimelike)\n",
            "        1    0.000    0.000    0.000    0.000 common.py:127(<lambda>)\n",
            "        3    0.000    0.000    0.000    0.000 common.py:131(is_object_dtype)\n",
            "        1    0.000    0.000    0.000    0.000 common.py:1513(is_string_like_dtype)\n",
            "        1    0.000    0.000    0.000    0.000 common.py:1542(<lambda>)\n",
            "        2    0.000    0.000    0.000    0.000 common.py:160(is_sparse)\n",
            "        1    0.000    0.000    0.000    0.000 common.py:1643(is_extension_type)\n",
            "        2    0.000    0.000    0.000    0.000 common.py:1702(is_extension_array_dtype)\n",
            "        2    0.000    0.000    0.000    0.000 common.py:1784(_is_dtype)\n",
            "        2    0.000    0.000    0.000    0.000 common.py:1809(_get_dtype)\n",
            "        4    0.000    0.000    0.000    0.000 common.py:1845(_is_dtype_type)\n",
            "        1    0.000    0.000    0.000    0.000 common.py:1981(pandas_dtype)\n",
            "        2    0.000    0.000    0.000    0.000 common.py:262(is_categorical)\n",
            "        2    0.000    0.000    0.000    0.000 common.py:434(is_datetime64tz_dtype)\n",
            "        2    0.000    0.000    0.000    0.000 common.py:503(is_period_dtype)\n",
            "        1    0.000    0.000    0.000    0.000 common.py:536(is_interval_dtype)\n",
            "        2    0.000    0.000    0.000    0.000 common.py:572(is_categorical_dtype)\n",
            "        1    0.000    0.000    0.000    0.000 common.py:605(is_string_dtype)\n",
            "        1    0.000    0.000    0.000    0.000 common.py:634(condition)\n",
            "        1    0.000    0.000    0.000    0.000 common.py:868(is_integer_dtype)\n",
            "        1    0.000    0.000    0.000    0.000 construction.py:537(sanitize_array)\n",
            "        1    0.000    0.000    0.000    0.000 construction.py:684(_try_cast)\n",
            "        1    0.000    0.000    0.000    0.000 contextlib.py:157(helper)\n",
            "        1    0.000    0.000    0.000    0.000 contextlib.py:59(__init__)\n",
            "        1    0.000    0.000    0.016    0.016 contextlib.py:79(__enter__)\n",
            "        1    0.000    0.000    0.000    0.000 contextlib.py:85(__exit__)\n",
            "        1    0.000    0.000    0.079    0.079 decoder.py:334(decode)\n",
            "        1    0.078    0.078    0.078    0.078 decoder.py:345(raw_decode)\n",
            "        2    0.000    0.000    0.000    0.000 dtypes.py:68(find)\n",
            "        2    0.000    0.000    0.000    0.000 dtypes.py:827(is_dtype)\n",
            "        1    0.000    0.000    0.000    0.000 dtypes.py:973(is_dtype)\n",
            "        2    0.000    0.000    0.000    0.000 function_base.py:2031(__init__)\n",
            "        1    0.000    0.000    0.000    0.000 function_base.py:2048(<listcomp>)\n",
            "        2    0.000    0.000    0.000    0.000 function_base.py:2063(__call__)\n",
            "        2    0.000    0.000    0.000    0.000 function_base.py:2093(_get_ufunc_and_otypes)\n",
            "        1    0.000    0.000    0.000    0.000 function_base.py:2115(<listcomp>)\n",
            "        2    0.000    0.000    0.000    0.000 function_base.py:2116(<genexpr>)\n",
            "        1    0.000    0.000    0.000    0.000 function_base.py:2120(<listcomp>)\n",
            "        1    0.000    0.000    0.000    0.000 function_base.py:2144(<listcomp>)\n",
            "        2    0.000    0.000    0.000    0.000 function_base.py:2154(_vectorize_call)\n",
            "        2    0.000    0.000    0.000    0.000 function_base.py:2164(<listcomp>)\n",
            "        2    0.000    0.000    0.000    0.000 function_base.py:258(iterable)\n",
            "        1    0.000    0.000    0.000    0.000 generic.py:127(__init__)\n",
            "        1    0.000    0.000    0.000    0.000 generic.py:5053(__getattr__)\n",
            "        1    0.000    0.000    0.000    0.000 generic.py:5069(__setattr__)\n",
            "       36    0.000    0.000    0.000    0.000 generic.py:7(_check)\n",
            "        1    0.000    0.000    0.000    0.000 genericpath.py:16(exists)\n",
            "        1    0.000    0.000    0.000    0.000 gzip.py:123(__init__)\n",
            "        1    0.000    0.000    0.000    0.000 gzip.py:20(open)\n",
            "        1    0.000    0.000    0.015    0.015 gzip.py:271(read)\n",
            "        8    0.000    0.000    0.000    0.000 gzip.py:298(closed)\n",
            "        1    0.000    0.000    0.000    0.000 gzip.py:302(close)\n",
            "        1    0.000    0.000    0.000    0.000 gzip.py:321(flush)\n",
            "        1    0.000    0.000    0.000    0.000 gzip.py:328(fileno)\n",
            "        1    0.000    0.000    0.000    0.000 gzip.py:343(readable)\n",
            "        1    0.000    0.000    0.000    0.000 gzip.py:346(writable)\n",
            "        1    0.000    0.000    0.000    0.000 gzip.py:349(seekable)\n",
            "        1    0.000    0.000    0.000    0.000 gzip.py:378(__init__)\n",
            "        2    0.000    0.000    0.000    0.000 gzip.py:385(_init_read)\n",
            "        2    0.000    0.000    0.000    0.000 gzip.py:389(_read_exact)\n",
            "        2    0.000    0.000    0.000    0.000 gzip.py:405(_read_gzip_header)\n",
            "      250    0.001    0.000    0.015    0.000 gzip.py:438(read)\n",
            "      249    0.000    0.000    0.002    0.000 gzip.py:489(_add_read_data)\n",
            "        1    0.000    0.000    0.000    0.000 gzip.py:493(_read_eof)\n",
            "        1    0.000    0.000    0.000    0.000 gzip.py:74(__init__)\n",
            "      263    0.000    0.000    0.001    0.000 gzip.py:80(read)\n",
            "      249    0.000    0.000    0.000    0.000 gzip.py:93(prepend)\n",
            "        2    0.000    0.000    0.000    0.000 inference.py:253(is_list_like)\n",
            "        1    0.000    0.000    0.000    0.000 inference.py:438(is_hashable)\n",
            "        1    0.000    0.000    0.000    0.000 managers.py:1443(__init__)\n",
            "        2    0.000    0.000    0.000    0.000 managers.py:1488(_block)\n",
            "        2    0.000    0.000    0.000    0.000 managers.py:1546(external_values)\n",
            "        1    0.000    0.000    0.000    0.000 managers.py:206(items)\n",
            "        1    0.000    0.000    0.000    0.000 managers.py:291(__len__)\n",
            "        1    0.000    0.000    0.000    0.000 missing.py:105(_isna_new)\n",
            "        1    0.000    0.000    0.000    0.000 missing.py:183(_isna_ndarraylike)\n",
            "        1    0.000    0.000    0.000    0.000 missing.py:25(isna)\n",
            "        1    0.000    0.000    0.000    0.000 numeric.py:113(is_all_dates)\n",
            "        2    0.000    0.000    0.000    0.000 numeric.py:469(asarray)\n",
            "        4    0.000    0.000    0.000    0.000 numerictypes.py:293(issubclass_)\n",
            "        2    0.000    0.000    0.000    0.000 numerictypes.py:365(issubdtype)\n",
            "        1    0.000    0.000    0.000    0.000 posixpath.py:154(dirname)\n",
            "        2    0.000    0.000    0.000    0.000 posixpath.py:41(_get_sep)\n",
            "        1    0.000    0.000    0.000    0.000 posixpath.py:75(join)\n",
            "        4    0.000    0.000    0.000    0.000 range.py:510(__len__)\n",
            "        1    0.000    0.000    0.000    0.000 series.py:152(__init__)\n",
            "        1    0.000    0.000    0.000    0.000 series.py:338(_constructor)\n",
            "        1    0.000    0.000    0.000    0.000 series.py:354(_set_axis)\n",
            "        1    0.000    0.000    0.000    0.000 series.py:382(_set_subtyp)\n",
            "        2    0.000    0.000    0.000    0.000 series.py:392(name)\n",
            "        1    0.000    0.000    0.000    0.000 series.py:399(name)\n",
            "        2    0.000    0.000    0.000    0.000 series.py:434(values)\n",
            "        1    0.000    0.000    0.000    0.000 series.py:591(__len__)\n",
            "        7    0.000    0.000    0.000    0.000 spellchecker.py:102(word_probability)\n",
            "        7    0.000    0.000    0.000    0.000 spellchecker.py:118(correction)\n",
            "        7    0.000    0.000    0.000    0.000 spellchecker.py:127(candidates)\n",
            "        7    0.000    0.000    0.000    0.000 spellchecker.py:149(known)\n",
            "        7    0.000    0.000    0.000    0.000 spellchecker.py:158(<listcomp>)\n",
            "       14    0.000    0.000    0.000    0.000 spellchecker.py:160(<genexpr>)\n",
            "        3    0.000    0.000    0.000    0.000 spellchecker.py:166(unknown)\n",
            "        3    0.000    0.000    0.000    0.000 spellchecker.py:175(<listcomp>)\n",
            "        5    0.000    0.000    0.000    0.000 spellchecker.py:176(<genexpr>)\n",
            "       11    0.000    0.000    0.000    0.000 spellchecker.py:224(_check_if_should_check)\n",
            "        1    0.000    0.000    0.000    0.000 spellchecker.py:243(__init__)\n",
            "       25    0.000    0.000    0.000    0.000 spellchecker.py:266(dictionary)\n",
            "        7    0.000    0.000    0.000    0.000 spellchecker.py:275(total_words)\n",
            "        1    0.000    0.000    0.168    0.168 spellchecker.py:28(__init__)\n",
            "        1    0.002    0.002    0.167    0.167 spellchecker.py:320(load_dictionary)\n",
            "        1    0.024    0.024    0.056    0.056 spellchecker.py:401(_update_dictionary)\n",
            "        1    0.000    0.000    0.000    0.000 spellchecker.py:70(distance)\n",
            "        1    0.000    0.000    0.000    0.000 strings.py:1313(str_split)\n",
            "        2    0.000    0.000    0.000    0.000 strings.py:1318(<lambda>)\n",
            "        1    0.000    0.000    0.000    0.000 strings.py:1854(_wrap_result)\n",
            "        1    0.000    0.000    0.001    0.001 strings.py:2388(split)\n",
            "        1    0.000    0.000    0.000    0.000 strings.py:57(_na_map)\n",
            "        1    0.000    0.000    0.000    0.000 strings.py:62(_map)\n",
            "        2    0.000    0.000    0.016    0.008 utils.py:15(load_file)\n",
            "        1    0.001    0.001    0.001    0.001 {built-in method _codecs.utf_8_decode}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method _locale.nl_langinfo}\n",
            "        2    0.000    0.000    0.000    0.000 {built-in method _struct.unpack}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
            "        1    0.000    0.000    0.171    0.171 {built-in method builtins.exec}\n",
            "       51    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
            "       11    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method builtins.hash}\n",
            "       76    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
            "       20    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
            "        2    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
            "  781/779    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
            "       11    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
            "        2    0.000    0.000    0.016    0.008 {built-in method builtins.next}\n",
            "        1    0.001    0.001    0.001    0.001 {built-in method builtins.sum}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method io.open}\n",
            "        9    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
            "        2    0.000    0.000    0.000    0.000 {built-in method numpy.frompyfunc}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method pandas._libs.missing.isnaobj}\n",
            "        3    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
            "        1    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
            "      251    0.002    0.000    0.002    0.000 {built-in method zlib.crc32}\n",
            "        2    0.000    0.000    0.000    0.000 {built-in method zlib.decompressobj}\n",
            "        1    0.013    0.013    0.013    0.013 {function Counter.update at 0x7f6f36c55c80}\n",
            "        1    0.000    0.000    0.000    0.000 {function DecompressReader.close at 0x7f6f368e69d8}\n",
            "        7    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
            "        2    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
            "      249    0.011    0.000    0.011    0.000 {method 'decompress' of 'zlib.Decompress' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
            "        2    0.000    0.000    0.000    0.000 {method 'end' of '_sre.SRE_Match' objects}\n",
            "        2    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'fileno' of '_io.BufferedReader' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
            "        2    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
            "       20    0.002    0.000    0.002    0.000 {method 'lower' of 'str' objects}\n",
            "        2    0.000    0.000    0.000    0.000 {method 'match' of '_sre.SRE_Pattern' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
            "    263/1    0.001    0.000    0.015    0.015 {method 'read' of '_io.BufferedReader' objects}\n",
            "        1    0.000    0.000    0.016    0.016 {method 'read' of '_io.TextIOWrapper' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'replace' of 'str' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'rstrip' of 'str' objects}\n",
            "        2    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
            "        4    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
            "   118292    0.031    0.000    0.031    0.000 {method 'update' of 'set' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
            "        1    0.000    0.000    0.000    0.000 {pandas._libs.algos.ensure_object}\n",
            "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_datetimelike_array}\n",
            "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.infer_dtype}\n",
            "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.is_scalar}\n",
            "        1    0.000    0.000    0.000    0.000 {pandas._libs.lib.map_infer_mask}\n",
            "\n",
            "\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY9ZG5OsyPFH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "misspelledWords = checkMisspellings(trainingData[\"answer_text\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjLYDGAUujy4",
        "colab_type": "text"
      },
      "source": [
        "#### Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pkJ61xyU-LjU",
        "colab_type": "code",
        "outputId": "73c77830-8ebd-41c8-adea-c834ff5a1a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "from sys import getsizeof\n",
        "def vocabulary():\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "  data_frame = trainingData + devData\n",
        "  data_frame = data_frame.astype(\"str\")\n",
        "  phrases = []\n",
        "  for idx,row in data_frame.iterrows():\n",
        "    phrases.append(row[\"question\"])\n",
        "    phrases.append(row[\"paragraph_context\"])\n",
        "    phrases.append(row[\"article_title\"])\n",
        "  for string in phrases:\n",
        "    assert \"catalanswhat\" not in str(string)\n",
        "  words = CountVectorizer().fit(phrases).get_feature_names()\n",
        "  assert \"raisedin\" not in words\n",
        "  return words\n",
        "def vocabularySize():\n",
        "  return len(vocabulary())\n",
        "def summaryStatistics(series):\n",
        "    numberOfWords = series.apply(lambda x: len(str(x).split(\" \")))\n",
        "    averageNumberOfWords = sum(numberOfWords) / len(numberOfWords)\n",
        "    return \"average: \" + str(averageNumberOfWords) + \"maximum: \" + str(max(numberOfWords)) + \" minimum: \" +str(min(numberOfWords))\n",
        "print(\"Size of vocabulary: \", vocabularySize())\n",
        "print(\"Words in each question: \",summaryStatistics(trainingData[\"question\"]))\n",
        "print(\"Words in each article title: \",summaryStatistics(trainingData[\"article_title\"]))\n",
        "print(\"Words in each context: \",summaryStatistics(trainingData[\"paragraph_context\"]))\n",
        "print(\"Words in each answer: \",summaryStatistics(trainingData[\"answer_text\"]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-31b454044432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0maverageNumberOfWords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumberOfWords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumberOfWords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"average: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverageNumberOfWords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"maximum: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumberOfWords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" minimum: \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumberOfWords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size of vocabulary: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabularySize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Words in each question: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msummaryStatistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Words in each article title: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msummaryStatistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"article_title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-31b454044432>\u001b[0m in \u001b[0;36mvocabularySize\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvocabularySize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummaryStatistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mnumberOfWords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-31b454044432>\u001b[0m in \u001b[0;36mvocabulary\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mphrases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"article_title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mphrases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0;34m\"catalanswhat\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m   \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0;34m\"raisedin\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8IUZ203W4qi",
        "colab_type": "text"
      },
      "source": [
        "####Get maximum ** possible** answer start.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnvr_TCH-Lkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "max_possible_answer_start = int(pd.concat((trainingData[\"answer_text\"],devData[\"answer_text\"])).str.len().max())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40XPLi7DW_Jd",
        "colab_type": "text"
      },
      "source": [
        "####Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGXSmR5M-Lk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ecPo0Jetse39"
      },
      "source": [
        "### Integer encode text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GCN8otUGse38"
      },
      "source": [
        "Used for manual encoding of text into integers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z19nkJI8iFmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "strings = pd.concat((trainingData,devData)).drop(\"answer_start\",axis=1)\n",
        "strings = strings.values.flatten()\n",
        "textTokenizer = Tokenizer()\n",
        "textTokenizer.fit_on_texts(strings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iymfrGtadU0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get length of vocabulary.\n",
        "vocabulary_length = len(textTokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh5c5MeLe2Z1",
        "colab_type": "code",
        "outputId": "132fb7b2-a9d0-4c80-dbdc-33a6108704ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "# Get maximum length of all questions and contexts.\n",
        "max_length_questions = pd.concat((trainingData[\"question\"],devData[\"question\"])).str.split().len().max\n",
        "max_length_context = pd.concat((trainingData[\"paragraph_context\"],devData[\"paragraph_context\"])).str.len().max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-b7a943cfd50e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_length_questions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax_length_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"paragraph_context\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"paragraph_context\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'len'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqbzwlpakw8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "questionsTokenized_train = pad_sequences(np.array(textTokenizer.texts_to_sequences(trainingData[\"question\"])),maxlen=max_length_questions)\n",
        "contextTokenized_train = pad_sequences(np.array(textTokenizer.texts_to_sequences(trainingData[\"paragraph_context\"])),maxlen=max_length_context)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXVcBRqidB6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "questionsTokenized_dev = textTokenizer.texts_to_sequences(devData[\"question\"])\n",
        "contextTokenized_dev = textTokenizer.texts_to_sequences(devData[\"paragraph_context\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_ZjWkiReXH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pad sequences.\n",
        "questionsTokenized_train = pad_sequences(questionsTokenized_train,maxlen=max_length_questions)\n",
        "contextTokenized_train = pad_sequences(contextTokenized_train,maxlen=max_length_context)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oq_sLBsSse3_"
      },
      "source": [
        "## Second neural network - non-recurrent/no transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IniJzW3lse3-"
      },
      "source": [
        "This neural network is used to generate answers from the questions and articles. It works by first reading the relevant article and using the question to find the answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V7fyv6DQse3V",
        "outputId": "c65b5ae6-734c-402a-a8cc-becdc1bfef98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "#Build the neural network.\n",
        "from math import log\n",
        "inputShape_second = X_2_train_num.shape[1:3]\n",
        "print(inputShape_second)\n",
        "answers_shape = Y_2_train_num.shape\n",
        "print(answers_shape[1])\n",
        "# Find the vocabulary length.\n",
        "vocabularyLength = np.concatenate((X_2_train_num,X_2_dev_num)).max() + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-056fa452021a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minputShape_second\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_2_train_num\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputShape_second\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0manswers_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_2_train_num\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_2_train_num' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Iv25QYbbse3Q",
        "outputId": "2b705537-b0fe-4934-ad3f-1ad0d6365054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "questions = Input(shape=(questionsTrain.shape[1],))\n",
        "context = Input(shape=(contextTrain.shape[1],))\n",
        "embedding_1 = Embedding(vocabularyLength,16)(questions)\n",
        "#answers_network.add(Dense(16))\n",
        "flatten_1 = Flatten()(embedding_1)\n",
        "hidden = Dense(16)(Dense(8)(flatten_1))\n",
        "hidden_2 = Dense(16)(hidden)\n",
        "hidden_3 = Dense(16)(hidden_2)\n",
        "dropout = Dropout(0.45)(hidden_3)\n",
        "output = Dense(answers_shape[1],activation='softmax')(dropout)\n",
        "answers_network = Model(inputs=[questions,context],outputs=output)\n",
        "answers_network.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7aff34f6a1d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquestions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestionsTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontextTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membedding_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabularyLength\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#answers_network.add(Dense(16))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mflatten_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'questionsTrain' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eTLaKjwyse3N",
        "colab": {}
      },
      "source": [
        "answers_network.compile(\"adam\",\"binary_crossentropy\",metrics=[f1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OSJyJ3qxse3L"
      },
      "source": [
        "#### Train the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IekQsi2Yse3J",
        "colab": {}
      },
      "source": [
        "answers_network_checkpoint = ModelCheckpoint('answers_network-non-rnn-best.h5', verbose=1, monitor='val_f1',save_best_only=True, mode='auto') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_tWTvWxSse3F",
        "colab": {}
      },
      "source": [
        "print(answers_network.metrics_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9hg2J0qBse3C",
        "colab": {}
      },
      "source": [
        "\n",
        "answers_network.fit(x=[questionsTrain,contextTrain],y=Y_2_train_num,callbacks=[answers_network_checkpoint],validation_split=0.2,verbose=True,epochs=9)\n",
        "#print(\"Weights: \",questions_article_model.get_weights())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LWDY4xhAse3A"
      },
      "source": [
        "#### Loading the model with best fit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rEudSH2Ese29",
        "colab": {}
      },
      "source": [
        "answers_network.load_weights('answers_network-non-rnn-best.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ewsndbURse24",
        "colab": {}
      },
      "source": [
        "\n",
        "answers_network.evaluate([questionsDev,contextDev],Y_2_dev_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT2h3iAU-LlT",
        "colab_type": "text"
      },
      "source": [
        "## Transfer learning using Google's Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGUwjE61-LlU",
        "colab_type": "text"
      },
      "source": [
        "Our model has a very poor F1 score. Let's see if we can't build a better model. We'll use Google's BERT deep learning network, which is so good that the networks with SQuaD 2.0's highest recorded F1 score use it.  \n",
        "\n",
        "The basic idea behind BERT is this: Neural networks rely on numerical vectors. Similar sentences and phrases should produce similar vectors.\n",
        "\n",
        "\"It is not possible to train bidirectional models by simply conditioning each word on words before and after it. Doing this would allow the word that’s being predicted to indirectly see itself in a multi-layer model. To solve this, Google researchers used a straightforward technique of masking out some words in the input and condition each word bidirectionally in order to predict the masked words. This idea is not new, but BERT is the first technique where it was successfully used to pre-train a deep neural network.\" (packtpub.com)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoEBVaLVikm-",
        "colab_type": "code",
        "outputId": "8344c6ab-df54-49ac-ca3f-eeb5bb9c045b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install wget # Used for downloading the BERT model.\n",
        "import wget\n",
        "import os\n",
        "import urllib\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFn0RZsHiPGZ",
        "colab_type": "code",
        "outputId": "83c06c03-c40c-4b3d-ace0-6d3bec04fdb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/google-research/bert.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'bert' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i3Hay_viTNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model_name = \"wwm_uncased_L-24_H-1024_A-16\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgJNfF_OifQC",
        "colab_type": "code",
        "outputId": "01d63cc0-c087-4977-8302-12a12a49ca62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bert_model_file_name = bert_model_name + \".zip\"\n",
        "online_bert_path = \"https://storage.googleapis.com/bert_models/2019_05_30/\" + bert_model_file_name\n",
        "if not os.path.isfile(bert_model_file_name):\n",
        "  wget.download(online_bert_path)\n",
        "  zipfile.ZipFile(bert_model_file_name,'r').extractall()\n",
        "print(os.path.abspath(bert_model_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/wwm_uncased_L-24_H-1024_A-16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svwSEHh1-Llb",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### The neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYxwvFi29eZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(currentDirectory)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOPb0C6oWxJp",
        "colab_type": "code",
        "outputId": "2c5cab97-d3c0-433d-aa3e-38ba9c9c941a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# @title Preparation\n",
        "!pip install -q keras-bert\n",
        "!wget -q https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!unzip -o uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9SNLQU--Llc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title Environment\n",
        "import os\n",
        "\n",
        "pretrained_path = 'uncased_L-12_H-768_A-12'\n",
        "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
        "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
        "vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
        "\n",
        "# TF_KERAS must be added to environment variables in order to use TPU\n",
        "os.environ['TF_KERAS'] = '1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzoNvlduX9mS",
        "colab_type": "code",
        "outputId": "3a2c786a-5901-4d12-8440-901e25a6e24a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# @title Load Basic Model\n",
        "import codecs\n",
        "from keras_bert import load_trained_model_from_checkpoint\n",
        "assert os.path.exists(pretrained_path), str(pretrained_path + \" does not exist\")\n",
        "token_dict = {}\n",
        "with codecs.open(vocab_path, 'r', 'utf8') as reader:\n",
        "    for line in reader:\n",
        "        token = line.strip()\n",
        "        token_dict[token] = len(token_dict)\n",
        "\n",
        "model = load_trained_model_from_checkpoint(config_path, checkpoint_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdDxlW5ZCTbQ",
        "colab_type": "code",
        "outputId": "86b596e3-5cb5-42e0-cc03-9a57ce02357e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4097
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Input-Token (InputLayer)        (None, 512)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Input-Segment (InputLayer)      (None, 512)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token (TokenEmbedding [(None, 512, 768), ( 23440896    Input-Token[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Segment (Embedding)   (None, 512, 768)     1536        Input-Segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Token-Segment (Add)   (None, 512, 768)     0           Embedding-Token[0][0]            \n",
            "                                                                 Embedding-Segment[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Position (PositionEmb (None, 512, 768)     393216      Embedding-Token-Segment[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Dropout (Dropout)     (None, 512, 768)     0           Embedding-Position[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Embedding-Norm (LayerNormalizat (None, 512, 768)     1536        Embedding-Dropout[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 512, 768)     2362368     Embedding-Norm[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 512, 768)     0           Embedding-Norm[0][0]             \n",
            "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-3-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-3-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-3-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-3-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-3-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-3-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-3-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-4-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-3-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-4-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-4-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-4-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-4-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-4-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-4-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-5-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-4-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-5-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-5-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-5-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-5-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-5-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-5-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-6-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-5-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-6-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-6-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-6-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-6-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-6-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-6-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-7-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-6-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-7-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-7-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-7-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-7-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-7-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-7-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-8-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-7-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-8-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-8-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-8-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-8-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-8-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 512, 768)     2362368     Encoder-8-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-9-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 512, 768)     0           Encoder-8-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-MultiHeadSelfAttentio (None, 512, 768)     1536        Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward (FeedForw (None, 512, 768)     4722432     Encoder-9-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Dropout ( (None, 512, 768)     0           Encoder-9-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Add (Add) (None, 512, 768)     0           Encoder-9-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-9-FeedForward-Norm (Lay (None, 512, 768)     1536        Encoder-9-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 512, 768)     2362368     Encoder-9-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-9-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-MultiHeadSelfAttenti (None, 512, 768)     1536        Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward (FeedFor (None, 512, 768)     4722432     Encoder-10-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Dropout  (None, 512, 768)     0           Encoder-10-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Add (Add (None, 512, 768)     0           Encoder-10-MultiHeadSelfAttention\n",
            "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-10-FeedForward-Norm (La (None, 512, 768)     1536        Encoder-10-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 512, 768)     2362368     Encoder-10-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-10-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-MultiHeadSelfAttenti (None, 512, 768)     1536        Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward (FeedFor (None, 512, 768)     4722432     Encoder-11-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Dropout  (None, 512, 768)     0           Encoder-11-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Add (Add (None, 512, 768)     0           Encoder-11-MultiHeadSelfAttention\n",
            "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-11-FeedForward-Norm (La (None, 512, 768)     1536        Encoder-11-FeedForward-Add[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 512, 768)     2362368     Encoder-11-FeedForward-Norm[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 512, 768)     0           Encoder-11-FeedForward-Norm[0][0]\n",
            "                                                                 Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-MultiHeadSelfAttenti (None, 512, 768)     1536        Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward (FeedFor (None, 512, 768)     4722432     Encoder-12-MultiHeadSelfAttention\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Dropout  (None, 512, 768)     0           Encoder-12-FeedForward[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Add (Add (None, 512, 768)     0           Encoder-12-MultiHeadSelfAttention\n",
            "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-12-FeedForward-Norm (La (None, 512, 768)     1536        Encoder-12-FeedForward-Add[0][0] \n",
            "==================================================================================================\n",
            "Total params: 108,891,648\n",
            "Trainable params: 0\n",
            "Non-trainable params: 108,891,648\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7H91K61DumE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# @title Initialize Variables\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "sess = K.get_session()\n",
        "uninitialized_variables = set([i.decode('ascii') for i in sess.run(tf.report_uninitialized_variables())])\n",
        "init_op = tf.variables_initializer(\n",
        "    [v for v in tf.global_variables() if v.name.split(':')[0] in uninitialized_variables]\n",
        ")\n",
        "sess.run(init_op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmhIYkSQD_h0",
        "colab_type": "code",
        "outputId": "ea9569c2-3933-4183-f389-b42dc0d7bb5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "# @title Convert to TPU Model\n",
        "import tensorflow as tf\n",
        "from keras_bert import get_custom_objects\n",
        "\n",
        "tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "strategy = tf.contrib.tpu.TPUDistributionStrategy(\n",
        "    tf.contrib.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\n",
        ")\n",
        "\n",
        "with tf.keras.utils.custom_object_scope(get_custom_objects()):\n",
        "    tpu_model = tf.contrib.tpu.keras_to_tpu_model(model, strategy=strategy)\n",
        "    tpu_model.compile('adam', 'sparse_categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.0.84.154:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 12467959691246213120)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 2858707863396374272)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4037339612110226200)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 10729005212180752397)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 3709303616099236915)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7109917871740969637)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 7271111281037069764)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 1897338595488246797)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3438067850351070324)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 15957760222744371682)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 5527112128479835238)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZhhwl6IECy4",
        "colab_type": "code",
        "outputId": "ff097a2a-34d0-4efa-936f-c70564140809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        }
      },
      "source": [
        "# @title Extraction\n",
        "import numpy as np\n",
        "from keras_bert import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(token_dict)\n",
        "text = 'From that day forth... my arm changed... and a voice echoed'\n",
        "tokens = tokenizer.tokenize(text)\n",
        "indices, segments = tokenizer.encode(first=text, max_len=512)\n",
        "print(tokens)\n",
        "\n",
        "with tf.keras.utils.custom_object_scope(get_custom_objects()):\n",
        "    predicts = tpu_model.predict([np.array([indices] * 8), np.array([segments] * 8)])[0]\n",
        "    \n",
        "for i, token in enumerate(tokens):\n",
        "    print(token, predicts[i].tolist()[:19])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'from', 'that', 'day', 'forth', '.', '.', '.', 'my', 'arm', 'changed', '.', '.', '.', 'and', 'a', 'voice', 'echoed', '[SEP]']\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=infer (# of cores 8), [TensorSpec(shape=(1, 512), dtype=tf.float32, name='Input-Token_10'), TensorSpec(shape=(1, 512), dtype=tf.float32, name='Input-Segment_10')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Cloning Adam {'lr': 0.0010000000474974513, 'beta_1': 0.8999999761581421, 'beta_2': 0.9990000128746033, 'decay': 0.0, 'epsilon': 1e-07, 'amsgrad': False}\n",
            "INFO:tensorflow:Remapping placeholder for Input-Token\n",
            "INFO:tensorflow:Remapping placeholder for Input-Segment\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-53c926ae4185>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_object_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_custom_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpredicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpu_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1982\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1983\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1984\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       return training_arrays.predict_loop(\n\u001b[0;32m-> 1113\u001b[0;31m           self, x, batch_size=batch_size, verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1258\u001b[0m     \u001b[0minput_specs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfeed_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_input_specs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m     tpu_model_ops = self._tpu_model_ops_for_input_specs(input_specs,\n\u001b[0;32m-> 1260\u001b[0;31m                                                         infeed_manager)\n\u001b[0m\u001b[1;32m   1261\u001b[0m     \u001b[0minfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfeed_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_feed_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpu_model_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py\u001b[0m in \u001b[0;36m_tpu_model_ops_for_input_specs\u001b[0;34m(self, input_specs, infeed_manager)\u001b[0m\n\u001b[1;32m   1167\u001b[0m           self._tpu_assignment.num_towers, input_specs)\n\u001b[1;32m   1168\u001b[0m       new_tpu_model_ops = self._specialize_model(input_specs,\n\u001b[0;32m-> 1169\u001b[0;31m                                                  infeed_manager)\n\u001b[0m\u001b[1;32m   1170\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compilation_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshape_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_tpu_model_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_model_compiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tpu_model_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py\u001b[0m in \u001b[0;36m_specialize_model\u001b[0;34m(self, input_specs, infeed_manager)\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[0;31m# running on a different logical core.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m     compile_op, execute_op = tpu.split_compile_and_replicate(\n\u001b[0;32m-> 1079\u001b[0;31m         _model_fn, inputs=[[] for _ in range(self._tpu_assignment.num_towers)])\n\u001b[0m\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0;31m# Generate CPU side operations to enqueue features/labels and dequeue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\u001b[0m in \u001b[0;36msplit_compile_and_replicate\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0mvscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_custom_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcomputation_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m       \u001b[0mvscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_use_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_use_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    976\u001b[0m                   worker_name=self._tpu_assignment.worker_name)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cloned_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0;31m# When running on more than one core, concatenate outputs at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_clone_sequential_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_clone_functional_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m_clone_functional_model\u001b[0;34m(model, input_tensors)\u001b[0m\n\u001b[1;32m    159\u001b[0m           \u001b[0mcomputed_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m           output_tensors = generic_utils.to_list(layer(computed_tensor,\n\u001b[0;32m--> 161\u001b[0;31m                                                        **kwargs))\n\u001b[0m\u001b[1;32m    162\u001b[0m           \u001b[0mcomputed_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomputed_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;31m# In graph mode, failure to build the layer's graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;31m# implies a user-side bug. We don't catch exceptions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_bert/layers/embedding.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTokenEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'ReplicatedVariable' and 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEKhgXry-Lle",
        "colab_type": "code",
        "outputId": "c72d70b5-0a65-40a7-8b74-490b2c5eaa89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "\n",
        "answers_network.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_10 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_11 (InputLayer)           (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 128)          0           input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_9 (Lambda)               (None, 128)          0           input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 1024)         132096      lambda_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 1024)         132096      lambda_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 1024)         0           dense_11[0][0]                   \n",
            "                                                                 dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 1024)         0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 240)          246000      dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 510,192\n",
            "Trainable params: 510,192\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDLyZ09mzjD5",
        "colab_type": "code",
        "outputId": "a27b91f7-9d9a-41c4-9123-4184decdcef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "answers_network.compile(\"rmsprop\",\"categorical_crossentropy\",metrics=[f1])\n",
        "answers_network_checkpoint = ModelCheckpoint('answers_network-rnn-best.h5', verbose=1, monitor='val_loss',save_best_only=True, mode='auto')\n",
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  y=session.run(tf.one_hot(Y_2_train,max_answer_start+1))\n",
        "  print(X_2_train_text.shape)\n",
        "  print(y.shape)\n",
        "  x = np.hsplit(X_2_train_text,2)\n",
        "  answers_network.fit(x=x,y=y,callbacks=[answers_network_checkpoint],epochs=8,validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(87599, 2)\n",
            "(87599, 240)\n",
            "Train on 70079 samples, validate on 17520 samples\n",
            "Epoch 1/8\n",
            "70016/70079 [============================>.] - ETA: 0s - loss: 2.6111 - f1: 4.6314e-04\n",
            "Epoch 00001: val_loss improved from inf to 2.33924, saving model to answers_network-rnn-best.h5\n",
            "70079/70079 [==============================] - 39s 551us/sample - loss: 2.6113 - f1: 4.6272e-04 - val_loss: 2.3392 - val_f1: 0.0000e+00\n",
            "Epoch 2/8\n",
            "70048/70079 [============================>.] - ETA: 0s - loss: 2.5859 - f1: 0.0013\n",
            "Epoch 00002: val_loss did not improve from 2.33924\n",
            "70079/70079 [==============================] - 38s 535us/sample - loss: 2.5856 - f1: 0.0013 - val_loss: 2.3703 - val_f1: 0.0000e+00\n",
            "Epoch 3/8\n",
            "69952/70079 [============================>.] - ETA: 0s - loss: 2.5735 - f1: 8.0789e-04\n",
            "Epoch 00003: val_loss did not improve from 2.33924\n",
            "70079/70079 [==============================] - 39s 556us/sample - loss: 2.5742 - f1: 8.0641e-04 - val_loss: 2.3829 - val_f1: 4.9543e-04\n",
            "Epoch 4/8\n",
            "69984/70079 [============================>.] - ETA: 0s - loss: 2.5684 - f1: 0.0012\n",
            "Epoch 00004: val_loss did not improve from 2.33924\n",
            "70079/70079 [==============================] - 36s 521us/sample - loss: 2.5689 - f1: 0.0012 - val_loss: 2.3933 - val_f1: 0.0010\n",
            "Epoch 5/8\n",
            "70016/70079 [============================>.] - ETA: 0s - loss: 2.5665 - f1: 7.8677e-04\n",
            "Epoch 00005: val_loss did not improve from 2.33924\n",
            "70079/70079 [==============================] - 37s 525us/sample - loss: 2.5665 - f1: 7.8605e-04 - val_loss: 2.3944 - val_f1: 0.0010\n",
            "Epoch 6/8\n",
            "69952/70079 [============================>.] - ETA: 0s - loss: 2.5651 - f1: 6.1713e-04\n",
            "Epoch 00006: val_loss did not improve from 2.33924\n",
            "70079/70079 [==============================] - 37s 528us/sample - loss: 2.5655 - f1: 6.1600e-04 - val_loss: 2.3831 - val_f1: 0.0000e+00\n",
            "Epoch 7/8\n",
            "70048/70079 [============================>.] - ETA: 0s - loss: 2.5652 - f1: 1.6678e-04\n",
            "Epoch 00007: val_loss did not improve from 2.33924\n",
            "70079/70079 [==============================] - 37s 521us/sample - loss: 2.5654 - f1: 1.6670e-04 - val_loss: 2.3911 - val_f1: 0.0000e+00\n",
            "Epoch 8/8\n",
            "70016/70079 [============================>.] - ETA: 0s - loss: 2.5689 - f1: 2.3010e-04\n",
            "Epoch 00008: val_loss did not improve from 2.33924\n",
            "70079/70079 [==============================] - 36s 515us/sample - loss: 2.5687 - f1: 2.2989e-04 - val_loss: 2.3783 - val_f1: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}